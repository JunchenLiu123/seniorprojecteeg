{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XDAWN Decoding from EEG data\n",
    "* XDAWN converts channels and events to create feature vectors that can be fed into a logistic regression ([MNE documentation](https://www.martinos.org/mne/stable/auto_examples/decoding/plot_decoding_xdawn_eeg.html))\n",
    "* This is a first attempt at exploring machine learning with EEG data. This method will produce a confusion matrix of event_ids.\n",
    "* Note: This code is NOT mine, but is taken from the link above and adjusted for data used in project.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import mne\n",
    "from mne import io, pick_types, read_events, Epochs\n",
    "# from mne.datasets import sample\n",
    "from mne.preprocessing import Xdawn\n",
    "from mne.decoding import Vectorizer\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "#data path for each run of each subject.\n",
    "drive_data_path = 'E:\\eeg_data'\n",
    "\n",
    "#data path on my external hdd for folder containing all tests of each subject in one file\n",
    "drive_all_data_path = 'E:\\eeg_data\\ica_140_500_0.1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentations starts with raw data, however we alreaday have epoched data with events and event id's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading E:\\eeg_data/Ex10_Suj1_Run1-epo.fif ...\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\eeg_data/Ex10_Suj1_Run1-epo.fif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ab803aacdf03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs = mne.read_epochs(op.join(drive_data_path, 'Ex10_Suj1_Run1-epo.fif'),\n\u001b[0;32m----> 2\u001b[0;31m                           preload=True)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# epochs.info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/epochs.pyc\u001b[0m in \u001b[0;36mread_epochs\u001b[0;34m(fname, proj, preload, verbose)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/utils.pyc\u001b[0m in \u001b[0;36mverbose\u001b[0;34m(function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0muse_log_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/epochs.pyc\u001b[0m in \u001b[0;36mread_epochs\u001b[0;34m(fname, proj, preload, verbose)\u001b[0m\n\u001b[1;32m   2332\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m     \"\"\"\n\u001b[0;32m-> 2334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mEpochsFIF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/epochs.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fname, proj, preload, verbose)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/utils.pyc\u001b[0m in \u001b[0;36mverbose\u001b[0;34m(function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0muse_log_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/epochs.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fname, proj, preload, verbose)\u001b[0m\n\u001b[1;32m   2393\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading %s ...'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m             \u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiff_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m             \u001b[0mnext_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m             (info, data, data_tag, events, event_id, tmin, tmax, baseline,\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/io/open.pyc\u001b[0m in \u001b[0;36mfiff_open\u001b[0;34m(fname, preload, verbose)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/utils.pyc\u001b[0m in \u001b[0;36mverbose\u001b[0;34m(function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0muse_log_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/io/open.pyc\u001b[0m in \u001b[0;36mfiff_open\u001b[0;34m(fname, preload, verbose)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fiff_get_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;31m# do preloading of entire file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py27/lib/python2.7/site-packages/mne/io/open.pyc\u001b[0m in \u001b[0;36m_fiff_get_fid\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using normal I/O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Open in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\eeg_data/Ex10_Suj1_Run1-epo.fif'"
     ]
    }
   ],
   "source": [
    "epochs = mne.read_epochs(op.join(drive_data_path, 'Ex10_Suj1_Run1-epo.fif'),\n",
    "                          preload=True)\n",
    "# epochs.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 61st channel produces an error when computin eigenvalues with cross-validation.\n",
    "# will use channels 0-60 instead.\n",
    "epochs = epochs.pick_channels(epochs.ch_names[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create classification pipeline\n",
    "clf = make_pipeline(Xdawn(n_components = 3),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LogisticRegression(penalty='l2'))\n",
    "#cross validator\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "#Do cross-validation\n",
    "labels = epochs.events[:,-1]\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(epochs, labels):\n",
    "    clf.fit(epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(epochs[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['after', 'before', 'new', 'scramble']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low accuracy scores, I must do more testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Normalized Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(epochs[test],labels[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create classification pipeline\n",
    "clf = make_pipeline(Xdawn(n_components = 3),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    RandomForestClassifier())\n",
    "\n",
    "#cross validator\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "#Do cross-validation\n",
    "labels = epochs.events[:,-1]\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(epochs, labels):\n",
    "    clf.fit(epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(epochs[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#very low score on test values\n",
    "clf.score(epochs[test],labels[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry with all results of a subject in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.read_epochs(op.join(drive_all_data_path, 'Subject1_all_runs-epo.fif'),\n",
    "preload=True)\n",
    "# epochs.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 61st channel produces an error when computin eigenvalues with cross-validation.\n",
    "# will use channels 0-60 instead.\n",
    "epochs = epochs.pick_channels(epochs.ch_names[:5])\n",
    "\n",
    "#create classification pipeline\n",
    "clf = make_pipeline(Xdawn(n_components = 3),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "#cross validator\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "#Do cross-validation\n",
    "labels = epochs.events[:,-1]\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(epochs, labels):\n",
    "    clf.fit(epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(epochs[test])\n",
    "    \n",
    "target_names = ['after', 'before', 'new', 'scramble']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Normalized Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(epochs[test],labels[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify New image versus Scrambled.\n",
    "Adjust the above code to just classify new versus scrambled images. Converting this to a binary classifcation problem may have more success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get epochs that only have event_id 'scrambled' and 'new'\n",
    "\n",
    "epochs_binary = mne.read_epochs(op.join(drive_data_path, 'Ex10_Suj1_Run1-epo.fif'),\n",
    "                          preload=True)\n",
    "#print shape for reference. \n",
    "epochs_binary._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_binary.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only events with id 4 or 5 (new or scrambled)\n",
    "epochs_binary = epochs_binary[(epochs_binary.events[:,-1] == 4) | (epochs_binary.events[:,-1] == 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs decreased from 280 to 141 due to filtering event_id's 4 and 5.\n",
    "print(epochs_binary._data.shape)\n",
    "\n",
    "# Also need to exclude channel 61\n",
    "epochs_binary = epochs_binary.pick_channels(epochs_binary.ch_names[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification Results\n",
    "* Flitering for event_id 4 and 5 greatly improved results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(Xdawn(n_components = 3),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "#cross validator\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "#Do cross-validation\n",
    "labels_binary = epochs_binary.events[:,-1]\n",
    "preds_binary = np.empty(len(labels_binary))\n",
    "for train, test in cv.split(epochs_binary, labels_binary):\n",
    "    clf.fit(epochs_binary[train], labels_binary[train])\n",
    "    preds_binary[test] = clf.predict(epochs_binary[test])\n",
    "    \n",
    "target_names = ['new', 'scramble']\n",
    "report = classification_report(labels_binary, preds_binary, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm = confusion_matrix(labels_binary, preds_binary)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Normalized Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(epochs_binary[test],labels_binary[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
