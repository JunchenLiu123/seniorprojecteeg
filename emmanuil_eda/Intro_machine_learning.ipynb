{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XDAWN Decoding from EEG data\n",
    "* XDAWN converts channels and events to create feature vectors that can be fed into a logistic regression ([MNE documentation](https://www.martinos.org/mne/stable/auto_examples/decoding/plot_decoding_xdawn_eeg.html))\n",
    "* This is a first attempt at exploring machine learning with EEG data. This method will produce a confusion matrix of event_ids.\n",
    "* Note: This code is NOT mine, but is taken from the link above and adjusted for data used in project.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import mne\n",
    "from mne import io, pick_types, read_events, Epochs\n",
    "# from mne.datasets import sample\n",
    "from mne.preprocessing import Xdawn\n",
    "from mne.decoding import Vectorizer\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "#data path for each run of each subject.\n",
    "drive_data_path = 'E:\\eeg_data'\n",
    "\n",
    "#data path on my external hdd for folder containing all tests of each subject in one file\n",
    "drive_all_data_path = 'E:\\eeg_data\\ica_140_500_0.1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentations starts with raw data, however we alreaday have epoched data with events and event id's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.read_epochs(op.join(drive_data_path, 'Ex10_Suj1_Run1-epo.fif'),\n",
    "                          preload=True)\n",
    "# epochs.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 61st channel produces an error when computin eigenvalues with cross-validation.\n",
    "# will use channels 0-60 instead.\n",
    "epochs = epochs.pick_channels(epochs.ch_names[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create classification pipeline\n",
    "clf = make_pipeline(Xdawn(n_components = 3),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LogisticRegression(penalty='l2'))\n",
    "#cross validator\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "#Do cross-validation\n",
    "labels = epochs.events[:,-1]\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(epochs, labels):\n",
    "    clf.fit(epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(epochs[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['after', 'before', 'new', 'scramble']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low accuracy scores, I must do more testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Normalized Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(epochs[test],labels[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create classification pipeline\n",
    "clf = make_pipeline(Xdawn(n_components = 3),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    RandomForestClassifier())\n",
    "\n",
    "#cross validator\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "#Do cross-validation\n",
    "labels = epochs.events[:,-1]\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(epochs, labels):\n",
    "    clf.fit(epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(epochs[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#very low score on test values\n",
    "clf.score(epochs[test],labels[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry with all results of a subject in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.read_epochs(op.join(drive_all_data_path, 'Subject1_all_runs-epo.fif'),\n",
    "preload=True)\n",
    "# epochs.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 61st channel produces an error when computin eigenvalues with cross-validation.\n",
    "# will use channels 0-60 instead.\n",
    "epochs = epochs.pick_channels(epochs.ch_names[:5])\n",
    "\n",
    "#create classification pipeline\n",
    "clf = make_pipeline(Xdawn(n_components = 3),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "#cross validator\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "#Do cross-validation\n",
    "labels = epochs.events[:,-1]\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(epochs, labels):\n",
    "    clf.fit(epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(epochs[test])\n",
    "    \n",
    "target_names = ['after', 'before', 'new', 'scramble']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Normalized Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(epochs[test],labels[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify New image versus Scrambled.\n",
    "Adjust the above code to just classify new versus scrambled images. Converting this to a binary classifcation problem may have more success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get epochs that only have event_id 'scrambled' and 'new'\n",
    "\n",
    "epochs_binary = mne.read_epochs(op.join(drive_data_path, 'Ex10_Suj1_Run1-epo.fif'),\n",
    "                          preload=True)\n",
    "#print shape for reference. \n",
    "epochs_binary._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_binary.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only events with id 4 or 5 (new or scrambled)\n",
    "epochs_binary = epochs_binary[(epochs_binary.events[:,-1] == 4) | (epochs_binary.events[:,-1] == 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs decreased from 280 to 141 due to filtering event_id's 4 and 5.\n",
    "print(epochs_binary._data.shape)\n",
    "\n",
    "# Also need to exclude channel 61\n",
    "epochs_binary = epochs_binary.pick_channels(epochs_binary.ch_names[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification Results\n",
    "* Flitering for event_id 4 and 5 greatly improved results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(Xdawn(n_components = 3),\n",
    "                    Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "#cross validator\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "#Do cross-validation\n",
    "labels_binary = epochs_binary.events[:,-1]\n",
    "preds_binary = np.empty(len(labels_binary))\n",
    "for train, test in cv.split(epochs_binary, labels_binary):\n",
    "    clf.fit(epochs_binary[train], labels_binary[train])\n",
    "    preds_binary[test] = clf.predict(epochs_binary[test])\n",
    "    \n",
    "target_names = ['new', 'scramble']\n",
    "report = classification_report(labels_binary, preds_binary, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm = confusion_matrix(labels_binary, preds_binary)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Normalized Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(epochs_binary[test],labels_binary[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
