{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2: Re-do initial classification on data \n",
    "Shateesh Bhugwansing\n",
    "\n",
    "This notebook attempts to build a pipeline to use the Naive Bayes classifer on Subject 1, runs 1-4, and of all runs of subject 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "#import mne to read EEG data \n",
    "import mne \n",
    "from mne.decoding import Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/Ex10_Suj1_Run1-epo.fif ...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 61) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    1400.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "280 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "280 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Reading /Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/Ex10_Suj1_Run2-epo.fif ...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 61) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    1400.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "285 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "285 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Reading /Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/Ex10_Suj1_Run3-epo.fif ...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 61) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    1400.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "287 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "287 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Reading /Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/Ex10_Suj1_Run4-epo.fif ...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 61) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    1400.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "293 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "293 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Reading /Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/subject1_all_runs-epo.fif ...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 61) active\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    1400.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1121 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1121 matching events found\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    }
   ],
   "source": [
    "#read in the data for the first 4 runs of subject 1, and all runs for subject1\n",
    "path1 = \"/Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/Ex10_Suj1_Run1-epo.fif\"\n",
    "path2 = \"/Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/Ex10_Suj1_Run2-epo.fif\"\n",
    "path3 = \"/Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/Ex10_Suj1_Run3-epo.fif\"\n",
    "path4 = \"/Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/Ex10_Suj1_Run4-epo.fif\"\n",
    "path_all = \"/Users/shateeshbhugwansing/Desktop/seniorprojecteeg/clean_data_sample/subject1_all_runs-epo.fif\"\n",
    "\n",
    "run1 = mne.read_epochs(path1, preload=True)\n",
    "run2 = mne.read_epochs(path2, preload=True)\n",
    "run3 = mne.read_epochs(path3, preload=True)\n",
    "run4 = mne.read_epochs(path4, preload=True)\n",
    "runs_all = mne.read_epochs(path_all, preload=True)\n",
    "\n",
    "# extract only the event_id's 4-5 for new vs. scrambled \n",
    "run1 = run1[(run1.events[:,-1] == 4) | (run1.events[:,-1] == 5)]\n",
    "run2 = run2[(run2.events[:,-1] == 4) | (run2.events[:,-1] == 5)]\n",
    "run3 = run3[(run3.events[:,-1] == 4) | (run3.events[:,-1] == 5)]\n",
    "run4 = run4[(run4.events[:,-1] == 4) | (run4.events[:,-1] == 5)]\n",
    "runs_all = runs_all[(runs_all.events[:,-1] == 4) | (runs_all.events[:,-1] == 5)]\n",
    "\n",
    "#store the actual data \n",
    "data1 = run1.get_data()\n",
    "data2 = run2.get_data()\n",
    "data3 = run3.get_data()\n",
    "data4 = run4.get_data()\n",
    "data_all = runs_all.get_data()\n",
    "\n",
    "#store labels (used as targets in the classifier algorithms)\n",
    "labels1 = run1.events[:,-1]\n",
    "labels2 = run2.events[:,-1]\n",
    "labels3 = run3.events[:,-1]\n",
    "labels4 = run4.events[:,-1]\n",
    "labels_all = runs_all.events[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attempt 1:\n",
    "data: data1\n",
    "cv: 10-fold CV  \n",
    "classifier pipeline: vectorizer --> MinMaxScaler --> BernoulliNB  \n",
    "metric: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Attempt1, data1: accuracy (%): ', 0.5319148936170213)\n"
     ]
    }
   ],
   "source": [
    "# make pipeline \n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                   StandardScaler(),\n",
    "                   BernoulliNB())\n",
    "\n",
    "#cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "preds1 = np.empty(len(labels1))\n",
    "\n",
    "#fit the classifier + make predictions\n",
    "for train, test in cv.split(data1, labels1):\n",
    "    clf.fit(data1[train], labels1[train])\n",
    "    preds1[test] = clf.predict(data1[test])\n",
    "\n",
    "\n",
    "print(\"Attempt1, data1: accuracy (%): \", metrics.accuracy_score(labels1, preds1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attempt 2: \n",
    "data: data_all  \n",
    "cv: 10-fold CV  \n",
    "classifier pipeline: vectorizer --> MinMaxScaler --> BernoulliNB  \n",
    "metric: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Attempt 2, data_all: accuracy (%): ', 0.7414721723518851)\n"
     ]
    }
   ],
   "source": [
    "# make pipeline \n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                   StandardScaler(),\n",
    "                   BernoulliNB())\n",
    "\n",
    "#cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "preds_all = np.empty(len(labels_all))\n",
    "\n",
    "#fit the classifier + make predictions\n",
    "for train, test in cv.split(data_all, labels_all):\n",
    "    clf.fit(data_all[train], labels_all[train])\n",
    "    preds_all[test] = clf.predict(data_all[test])\n",
    "\n",
    "\n",
    "print(\"Attempt 2, data_all: accuracy (%): \", metrics.accuracy_score(labels_all, preds_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3: \n",
    "data: data2  \n",
    "cv: 10-fold CV  \n",
    "classifier pipeline: vectorizer -->StandardScaler --> BernoulliNB\n",
    "metric: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Attempt 2, data2: accuracy (%): ', 0.6180555555555556)\n"
     ]
    }
   ],
   "source": [
    "# make pipeline \n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                   StandardScaler(),\n",
    "                   BernoulliNB())\n",
    "\n",
    "#cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "preds2 = np.empty(len(labels2))\n",
    "\n",
    "#fit the classifier + make predictions\n",
    "for train, test in cv.split(data2, labels2):\n",
    "    clf.fit(data2[train], labels2[train])\n",
    "    preds2[test] = clf.predict(data2[test])\n",
    "\n",
    "\n",
    "print(\"Attempt 2, data2: accuracy (%): \", metrics.accuracy_score(labels2, preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 85461)\n",
      "(144,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Vectorizer()\n",
    "new_data2 = vectorizer.fit_transform(data2)\n",
    "print((new_data2).shape)\n",
    "print(labels2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 4:\n",
    "data: data1  \n",
    "cv: ShuffleSplit  \n",
    "pipeline: CSP --> BernoulliNB  \n",
    "metric: accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CSP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5a490a025962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcsp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ledoit_wolf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CSP' is not defined"
     ]
    }
   ],
   "source": [
    "#set up pipeline + cross_val_score\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "csp = CSP(n_components=4, reg='ledoit_wolf', norm_trace=False)\n",
    "bnb = BernoulliNB()\n",
    "vectorizer = Vectorizer()\n",
    "scores = []\n",
    "\n",
    "clf2 = Pipeline([('CSP', csp), ('BernoulliNB', bnb)])\n",
    "scores = cross_val_score(clf2, data1, labels1, cv=cv, scoring='accuracy', n_jobs=1)\n",
    "print(\"Attempt 4: accuracy: \", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
