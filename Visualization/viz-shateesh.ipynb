{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of our EEG data \n",
    "A notebook with different methods to visualize our data and results of classification  \n",
    "Author: Shateesh Bhugwansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE (10/31): \n",
    "The sensor spacing is off. I need to figure out why.\n",
    "things to try (for next week):\n",
    "- plotting 2D position data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../preprocessing/StimCodes.ipynb\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Volumes/SB/EpochedEEG/20131216_1441_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "5424 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "5424 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# read in data \n",
    "epoch_path = '/Volumes/SB/EpochedEEG/20131216_1441_epo.fif'\n",
    "epoch = mne.read_epochs(epoch_path, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/shateeshbhugwansing/Desktop/seniorprojecteeg/Visualization/'\n",
    "montage = mne.channels.read_montage(kind=\"ANT_DukeWaveGuard_128_electrode_montage_copy\", ch_names=None, path=path, unit='mm', transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot_sensors();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot_sensors('3d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping coefficients to the channels\n",
    "Map the coefficients of Logistic Regression to the channels of the ANT Waveguard Duke cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ../preprocessing/Artifact_Removal/preprocecssing_helpers.ipynb\n",
    "# %run ../preprocessing/StimCodes.ipynb\n",
    "# %run ../Classification/ConcatEpochTrails.ipynb\n",
    "# %run ../PCA/Emmanuil-PCA.ipynb\n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stim_code_event_ids = {\n",
    "     \n",
    "    \"b-f2-wrd\":1,\n",
    "    \"b-f1-wrd\":2,\n",
    "    \"b-tg-wrd\":3,\n",
    "\n",
    "    \"b-f2-spk\":4,\n",
    "    \"b-f1-spk\":5,\n",
    "    \"b-tg-spk\":6,\n",
    "\n",
    "    \"b-f2-pic\":7,\n",
    "    \"b-f1-pic\":8,\n",
    "    \"b-tg-pic\":9,\n",
    "\n",
    "    \"b-f2-snd\":10,\n",
    "    \"b-f1-snd\":11,\n",
    "    \"b-tg-snd\":12,\n",
    "\n",
    "    \"f-f2-wrd\":13,\n",
    "    \"f-f1-wrd\":14,\n",
    "    \"f-tg-wrd\":15,\n",
    "\n",
    "    \"f-f2-spk\":16,\n",
    "    \"f-f1-spk\":17,\n",
    "    \"f-tg-spk\":18,\n",
    "\n",
    "    \"f-f2-pic\":19,\n",
    "    \"f-f1-pic\":20,\n",
    "    \"f-tg-pic\":21,\n",
    "\n",
    "    \"f-f2-snd\":22,\n",
    "    \"f-f1-snd\":23,\n",
    "    \"f-tg-snd\":24\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the following is from Emmanuil's Audio vs. Visual notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indicies of trials of epoch object\n",
    "trial_index_list = get_trial_index_list(epoch_object= epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new events for epoch object\n",
    "new_event_list = convert_event_ids_to_stim_combinations(epoch_object=epoch,\n",
    "                                                        trial_index_list = trial_index_list,\n",
    "                                                        stim_combinations = stim_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch.events.shape)\n",
    "print(new_event_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign new events to current epoch object\n",
    "epoch.events = new_event_list\n",
    "\n",
    "# assign new event_ids to current epoch object (dictionary \n",
    "# found in ../Classification/ConcatEpochTrails.ipynb)\n",
    " \n",
    "epoch.event_id = modality_lexicality_event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification time!\n",
    "\n",
    "# Isolate audio vs visual codes\n",
    "# audio codes are < 700, # visual codes are > 700 \n",
    "# audio : 100 , visual : 101\n",
    "for event in epoch.events:\n",
    "    if event[-1] < 700:\n",
    "        event[-1] = 100\n",
    "    else:\n",
    "        event[-1] = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pipe = make_pipeline(Vectorizer(), \n",
    "                          StandardScaler())\n",
    "norm_pipe.fit(epoch.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = norm_pipe.transform(epoch.get_data())\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do PCA to reduce dimensions and data needed for classification.\n",
    "# pca = UnsupervisedSpatialFilter(PCA(28), average=False) # PCA, keep 9 components \n",
    "\n",
    "epoch_data = epoch.get_data()\n",
    "# pca_data = pca.fit_transform(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(epoch_data))\n",
    "for train, test in cv.split(epoch_data, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(epoch_data[train], labels[train])\n",
    "    preds[test] = clf.predict(epoch_data[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio', 'Visual']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Emmanuil's classification code crashed. \n",
    "## Going to use what Tarekul did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topography Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projs = mne.compute_proj_epochs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_projs = epoch.add_proj(projs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(epoch_projs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_projs.plot_projs_topomap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot_projs_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topomap() is not working. Maybe I need to manaully create a layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
