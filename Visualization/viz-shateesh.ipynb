{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of our EEG data \n",
    "A notebook with different methods to visualize our data and results of classification  \n",
    "Author: Shateesh Bhugwansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE (10/31): \n",
    "The sensor spacing is off. I need to figure out why.\n",
    "things to try (for next week):\n",
    "- plotting 2D position data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ../preprocessing/StimCodes.ipynb\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# makes pop up window for plots\n",
    "%matplotlib qt \n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data \n",
    "epoch_path = '/Volumes/SB/EpochedEEG/20131216_1441_epo.fif'\n",
    "epoch = mne.read_epochs(epoch_path, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.read_montage(kind=\"ANT_DukeWaveGuard_128_electrode_montages_updated_V2\")\n",
    "# V2 is the version that's rotated to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 duplicate electrode labels found:\n",
      "RA2 /RA4 \n",
      "Plotting 124 unique labels.\n",
      "Channel names are not unique, found duplicates for: {'RA5 ', 'RR10'}. Applying running numbers for duplicates.\n",
      "The following EEG sensors did not have a position specified in the selected montage: ['RA5 -1', 'RR10-1']. Their position has been left untouched.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-8c0958edec32>:3: RuntimeWarning: Channel names are not unique, found duplicates for: {'RA5 ', 'RR10'}. Applying running numbers for duplicates.\n",
      "  montage.plot();\n",
      "<ipython-input-35-8c0958edec32>:3: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['RA5 -1', 'RR10-1']. Their position has been left untouched.\n",
      "  montage.plot();\n",
      "/Users/shateeshbhugwansing/anaconda/envs/mne/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 15\n",
    "montage.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v4 is the file with the channels in the correct orientation\n",
    "# had to manually transform the position array (x,y) --> (-y, x)\n",
    "montage2 = mne.channels.read_montage(kind=\"ANT_DukeWaveGuard_128_electrode_montages_updated_V4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 15\n",
    "\n",
    "montage2.plot(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot_sensors();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot_sensors('3d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing what the other montage file looks like (the example that Dave sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage2 = mne.channels.read_montage(kind=\"eetrak124.elc\", ch_names=None, path=path, unit='mm', transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage2.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing MNE, built in montage\n",
    "montage3 = mne.channels.read_montage('standard_1020')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage3.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check:\n",
    "What does the montage look like as a normal scatter plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(montage.pos[:,1], montage.pos[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try: manually editing the montage file columns so that the x axis is the first column, y axis is second\n",
    "montage_rotated = mne.channels.read_montage(kind=\"ANT_DukeWaveGuard_128_electrode_montage_rotated\", ch_names=None, path=path, unit='mm', transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_rotated.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '/Users/shateeshbhugwansing/Desktop/seniorprojecteeg/Visualization'\n",
    "montage = mne.channels.read_montage(kind='eetrak124', path=path2, unit='mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THEN WHY THE HECK IS IT ROTATED USING MONTAGE.PLOT??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping coefficients to the channels\n",
    "Map the coefficients of Logistic Regression to the channels of the ANT Waveguard Duke cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ../preprocessing/Artifact_Removal/preprocecssing_helpers.ipynb\n",
    "# %run ../preprocessing/StimCodes.ipynb\n",
    "# %run ../Classification/ConcatEpochTrails.ipynb\n",
    "# %run ../PCA/Emmanuil-PCA.ipynb\n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stim_code_event_ids = {\n",
    "     \n",
    "    \"b-f2-wrd\":1,\n",
    "    \"b-f1-wrd\":2,\n",
    "    \"b-tg-wrd\":3,\n",
    "\n",
    "    \"b-f2-spk\":4,\n",
    "    \"b-f1-spk\":5,\n",
    "    \"b-tg-spk\":6,\n",
    "\n",
    "    \"b-f2-pic\":7,\n",
    "    \"b-f1-pic\":8,\n",
    "    \"b-tg-pic\":9,\n",
    "\n",
    "    \"b-f2-snd\":10,\n",
    "    \"b-f1-snd\":11,\n",
    "    \"b-tg-snd\":12,\n",
    "\n",
    "    \"f-f2-wrd\":13,\n",
    "    \"f-f1-wrd\":14,\n",
    "    \"f-tg-wrd\":15,\n",
    "\n",
    "    \"f-f2-spk\":16,\n",
    "    \"f-f1-spk\":17,\n",
    "    \"f-tg-spk\":18,\n",
    "\n",
    "    \"f-f2-pic\":19,\n",
    "    \"f-f1-pic\":20,\n",
    "    \"f-tg-pic\":21,\n",
    "\n",
    "    \"f-f2-snd\":22,\n",
    "    \"f-f1-snd\":23,\n",
    "    \"f-tg-snd\":24\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the following is from Emmanuil's Audio vs. Visual notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indicies of trials of epoch object\n",
    "trial_index_list = get_trial_index_list(epoch_object= epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new events for epoch object\n",
    "new_event_list = convert_event_ids_to_stim_combinations(epoch_object=epoch,\n",
    "                                                        trial_index_list = trial_index_list,\n",
    "                                                        stim_combinations = stim_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch.events.shape)\n",
    "print(new_event_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign new events to current epoch object\n",
    "epoch.events = new_event_list\n",
    "\n",
    "# assign new event_ids to current epoch object (dictionary \n",
    "# found in ../Classification/ConcatEpochTrails.ipynb)\n",
    " \n",
    "epoch.event_id = modality_lexicality_event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification time!\n",
    "\n",
    "# Isolate audio vs visual codes\n",
    "# audio codes are < 700, # visual codes are > 700 \n",
    "# audio : 100 , visual : 101\n",
    "for event in epoch.events:\n",
    "    if event[-1] < 700:\n",
    "        event[-1] = 100\n",
    "    else:\n",
    "        event[-1] = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pipe = make_pipeline(Vectorizer(), \n",
    "                          StandardScaler())\n",
    "norm_pipe.fit(epoch.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = norm_pipe.transform(epoch.get_data())\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do PCA to reduce dimensions and data needed for classification.\n",
    "# pca = UnsupervisedSpatialFilter(PCA(28), average=False) # PCA, keep 9 components \n",
    "\n",
    "epoch_data = epoch.get_data()\n",
    "# pca_data = pca.fit_transform(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(epoch_data))\n",
    "for train, test in cv.split(epoch_data, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(epoch_data[train], labels[train])\n",
    "    preds[test] = clf.predict(epoch_data[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio', 'Visual']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emmanuil's classification code crashed. \n",
    "## Going to use what Tarekul did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_stim_code(epoch):\n",
    "    keys_to_delete = [x for x in epoch.event_id if 'stim' in x]\n",
    "    for key in keys_to_delete:\n",
    "        if 'stim' in key:\n",
    "            del epoch.event_id[key]\n",
    "            \n",
    "    for key in new_stim_code_event_ids:\n",
    "        epoch.event_id[key] = new_stim_code_event_ids[key]\n",
    "    \n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochWnewStim = update_stim_code(epoch)\n",
    "epochWnewStim.events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = epochWnewStim.events[:,-1]\n",
    "event_ids = epochWnewStim.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_combinations = {\n",
    "    (5,6,4): \"AALL\",\n",
    "    (17,18,16) :\"AALL\",\n",
    "    \n",
    "    (11,6,10):\"AALN\",\n",
    "    (23,18,22):\"AALN\",\n",
    "    \n",
    "    (5,12,4) :\"AANL\",\n",
    "    (17,24,16):\"AANL\",\n",
    "    \n",
    "    (11,12,10) : \"AANN\",\n",
    "    (23,24,22): \"AANN\",\n",
    "    \n",
    "    (2,6,1):\"AVLL\",\n",
    "    (14,18,13):\"AVLL\",\n",
    "    \n",
    "    (8,12,7):\"AVNN\",\n",
    "    (20,24,19):\"AVNN\",\n",
    "    \n",
    "    (5,3,4) :\"VALL\",\n",
    "    (17,15,16):\"VALL\",\n",
    "    \n",
    "    (11,9,10) :\"VANN\",\n",
    "    (23,21,22):\"VANN\",\n",
    "    \n",
    "    (2,3,1) :\"VVLL\",\n",
    "    (14,15,13):\"VVLL\",\n",
    "    \n",
    "    (8,3,7):\"VVLN\",\n",
    "    (20,15,19):\"VVLN\",\n",
    "    \n",
    "    (2,9,1) :\"VVNL\",\n",
    "    (14,21,13):\"VVNL\",\n",
    "    \n",
    "    (8,9,7) :\"VVNN\",\n",
    "    (20,21,19):\"VVNN\",\n",
    "    \n",
    "    (14,21,4):\"whatever\"\n",
    "    \n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = epochWnewStim.events\n",
    "events_new = []\n",
    "temp = []\n",
    "combo = []\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    if event[-1] == 31:\n",
    "        combo = []\n",
    "        for trialEpochs in temp:\n",
    "            if trialEpochs[-1] >=1 and trialEpochs[-1]<=24:\n",
    "                combo.append(trialEpochs[-1])\n",
    "        if len(combo) == 3: \n",
    "            combo_tuple = (combo[0],combo[1],combo[2]) \n",
    "            if stim_combinations[combo_tuple] == \"VVNN\" :\n",
    "                #print(combo_tuple)\n",
    "                for k in temp:\n",
    "                    if k[-1] >= 1 and k[-1] <= 24:\n",
    "                        #print(k)\n",
    "                        k[-1] = 100\n",
    "            elif stim_combinations[combo_tuple] == \"AANN\":\n",
    "                #print(combo_tuple)\n",
    "                for k in temp:\n",
    "                    if k[-1] >= 1 and k[-1] <= 24:\n",
    "                        #print(k)\n",
    "                        k[-1] = 200       \n",
    "            combo_tuple = []\n",
    "                \n",
    "        \n",
    "        for p in temp:\n",
    "            if p[-1] == 100 or p[-1] == 200:\n",
    "                events_new.append(p)\n",
    "#             if p[-1] >=1 and p[-1] <=24:\n",
    "#                 events_new.append(p)\n",
    "        temp = []\n",
    "        temp.append(event)\n",
    "    else:\n",
    "        temp.append(event)\n",
    "events_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New epoch with only visual stim code combinations\n",
    "test = epochWnewStim[(epochWnewStim.events[:,-1]==100) | (epochWnewStim.events[:,-1]==200)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#set features as epoch data\n",
    "#set targets as event ids\n",
    "features_data = test.get_data()\n",
    "target_V_vs_A = test.events[:,-1]\n",
    "\n",
    "print(\"shape of data\",features_data.shape)\n",
    "print(\"shape of target array\",target_V_vs_A.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new epoch with only events corresponding to 100 or 200(visual/audio stim codes)\n",
    "binaryEpoch = epochWnewStim[(epochWnewStim.events[:,-1]==100) | (epochWnewStim.events[:,-1]==200)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeling for converting data from 3D to 2D using vectorizer and\n",
    "#LogisticRegression for classification\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    MinMaxScaler(),\n",
    "                    (LogisticRegression(C=1)))\n",
    "\n",
    "#Provides train/test indices to split data in train/test sets.\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle=True)\n",
    "#y_preds = np.empty(len(target_V_vs_A))\n",
    "score = []\n",
    "# tprs = []\n",
    "# aucs = []\n",
    "# mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "#i = 0\n",
    "for train,test in cv.split(features_data,target_V_vs_A):\n",
    "    X_train = features_data[train] \n",
    "    #print(\"shape of training features(data):\",X_train.shape)\n",
    "    y_train = target_V_vs_A[train] \n",
    "    #print(\"shape of training target:\",y_train.shape)\n",
    "    X_test = features_data[test] \n",
    "    #print(\"shape of testing data:\",X_test.shape)\n",
    "    y_test = target_V_vs_A[test]\n",
    "    #print(\"shape of testing target:\",y_test.shape)\n",
    "    \n",
    "    #fit the model to training set\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #returns the mean accuracy on test data and labels\n",
    "    score.append(clf.score(X_test,y_test))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean classification score\", np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import get_coef\n",
    "#get the coeficients after fitting clf to training sets\n",
    "patterns2 = get_coef(clf,'coef_')\n",
    "#print(patterns2)\n",
    "\n",
    "#convert patterns2 to 129 x 180 array from 1 x 23220\n",
    "#take each block of 180 coeficients and put them together \n",
    "#for each channel. We will have 129 channels rows with\n",
    "#180 time columns\n",
    "hold = []\n",
    "for h in range(0,23219,180):\n",
    "    temp = []\n",
    "    for i in range(h,h+180):\n",
    "        temp.append(patterns2[0][i])\n",
    "    hold.append(temp)     \n",
    "npHold = np.array(hold)\n",
    "npHold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npHold_avg = []\n",
    "\n",
    "for i in range(len(npHold)):\n",
    "    npHold_avg.append(np.mean(npHold[i]))\n",
    "\n",
    "# npHold_avg = np.array(npHold_avg)\n",
    "print (len(npHold_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = epoch.ch_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_and_coeff = dict(zip(channels, npHold_avg))\n",
    "channels_and_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by observation, the averaged coefficients seem to be biggest on the scale of 0.001 \n",
    "\n",
    "coeff_of_interest = {k:v for (k,v) in channels_and_coeff.items() if abs(v) > 0.001 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the average didn't work. Trying a new approach\n",
    "# Interpolation of 2d data. \n",
    "# reference: https://docs.scipy.org/doc/scipy-0.14.0/reference/tutorial/interpolate.html#using-radial-basis-functions-for-smoothing-interpolation\n",
    "\n",
    "# set up x,y coordinates by taking the min, max of x,y coordinates of montage file. \n",
    "x_min = np.amin(montage.pos[:,1])\n",
    "x_max = np.amax(montage.pos[:,1])\n",
    "print (\"x range: \", x_max, x_min)\n",
    "\n",
    "y_min = np.amin(montage.pos[:,0])\n",
    "y_max = np.amax(montage.pos[:,0])\n",
    "print(\"y range: \", y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = np.linspace(y_min, y_max)\n",
    "yi = np.linspace(y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XI, YI = np.meshgrid(yi, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(XI).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid is set up. as for the data:\n",
    "# x = x-axis location of sensor (montage.pos[1])\n",
    "# y = y-axis location of sensor (montag.pos[0])\n",
    "# z = coefficient used in linear regression\n",
    "\n",
    "print( len(montage.pos[:,1]), len(montage.pos[:,0]), len(npHold_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(montage.ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: What I'm doing here is wrong. I should have filtered out the channels that are NOT the same in the epoch.ch_name and montage.ch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_coefficients = npHold_avg[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(averaged_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mine: \", type(x[0]), len(x), type(y[0]), len(y), type(z[0]), len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(npHold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up scattered data \n",
    "from scipy.interpolate import Rbf\n",
    "\n",
    "x = montage.pos[:,1]\n",
    "y = montage.pos[:,0]\n",
    "z = np.array(averaged_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to remove the duplicate x,y coordinates in order to get Rbf to work\n",
    "# NEED TO PRESERVE ORDER (can't sort them!!)\n",
    "\n",
    "def unique_unsorted(arr):\n",
    "    _, idx = np.unique(arr, return_index=True)\n",
    "    \n",
    "    return arr[np.sort(idx)], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_idx = unique_unsorted(x)\n",
    "y, y_idx  = unique_unsorted(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter z to get rid of the same indicies that the x array got rid of. \n",
    "z = z[np.sort(y_idx)]\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = Rbf(x,y,z, epsilon=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZI = rbf(XI, YI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "n = plt.Normalize(-2., 2.)\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.pcolor(XI, YI, ZI, cmap=cm.jet, alpha=0.2)\n",
    "plt.scatter(x, y, 100, z, cmap=cm.jet)\n",
    "plt.title('RBF interpolation - multiquadrics')\n",
    "plt.xlim(-.1, .1)\n",
    "plt.ylim(-.1, .1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try the same thing, with a different z-axis value. \n",
    "#### try z = npHold[0] ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = npHold[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = z2[np.sort(y_idx)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf2 = Rbf(x,y,z2, epsilon=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZI2 = rbf2(XI, YI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "n = plt.Normalize(-2., 2.)\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.pcolor(XI, YI, ZI2, cmap=cm.jet, alpha=0.2)\n",
    "plt.scatter(x, y, 100, z2, cmap=cm.jet)\n",
    "plt.title('RBF interpolation - Column 0')\n",
    "plt.xlim(-.1, .1)\n",
    "plt.ylim(-.1, .1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do this for a few other columns, to show change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3 = npHold[:,30]\n",
    "z4 = npHold[:,60]\n",
    "z5 = npHold[:,120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3 = z3[np.sort(y_idx)]\n",
    "z4 = z4[np.sort(y_idx)]\n",
    "z5 = z5[np.sort(y_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf3 = Rbf(x,y,z3, epsilon=2)\n",
    "rbf4 = Rbf(x,y,z4, epsilon=2)\n",
    "rbf5 = Rbf(x,y,z5, epsilon=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZI3 = rbf3(XI, YI)\n",
    "ZI4 = rbf4(XI, YI)\n",
    "ZI5 = rbf5(XI, YI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "n = plt.Normalize(-2., 2.)\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.pcolor(XI, YI, ZI3, cmap=cm.jet, alpha=0.2)\n",
    "plt.scatter(x, y, 100, z3, cmap=cm.jet)\n",
    "plt.title('RBF interpolation - column 30')\n",
    "plt.xlim(-.1, .1)\n",
    "plt.ylim(-.1, .1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "n = plt.Normalize(-2., 2.)\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.pcolor(XI, YI, ZI4, cmap=cm.jet, alpha=0.2)\n",
    "plt.scatter(x, y, 100, z4, cmap=cm.jet)\n",
    "plt.title('RBF interpolation - column 60')\n",
    "plt.xlim(-.1, .1)\n",
    "plt.ylim(-.1, .1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "n = plt.Normalize(-2., 2.)\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.pcolor(XI, YI, ZI5, cmap=cm.jet, alpha=0.2)\n",
    "plt.scatter(x, y, 100, z5, cmap=cm.jet)\n",
    "plt.title('RBF interpolation - column 120')\n",
    "plt.xlim(-.1, .1)\n",
    "plt.ylim(-.1, .1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topography Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projs = mne.compute_proj_epochs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_projs = epoch.add_proj(projs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(epoch_projs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_projs.plot_projs_topomap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot_projs_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topomap() is not working. Maybe I need to manaully create a layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
