{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Presentation Notebook\n",
    "By: Shateesh Bhugwansing\n",
    "### Perform my classification experiments from the semester on the entire data set\n",
    "\n",
    "Classifier: Linear SVM\n",
    "1. Audio vs. Visual\n",
    "2. Language vs. Non language\n",
    "\n",
    "##### NOTE: Run this on the CCNY Computing Node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emmanuil converted the data into larger, 2GB chunks that we can use at a time. \n",
    "\n",
    "epoch_path_1 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_1_epo.fif' \n",
    "epoch_path_2 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_2_epo.fif'\n",
    "epoch_path_3 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_3_epo.fif'\n",
    "epoch_path_4 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_4_epo.fif'\n",
    "epoch_path_5 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_5_epo.fif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_path = [epoch_path_1, epoch_path_2, epoch_path_3, epoch_path_4, epoch_path_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch1 = mne.read_epochs(epoch_path_1, preload=True)\n",
    "# epoch2 = mne.read_epochs(epoch_path_2, preload=True)\n",
    "# epoch3 = mne.read_epochs(epoch_path_3, preload=True)\n",
    "# epoch4 = mne.read_epochs(epoch_path_4, preload=True)\n",
    "# epoch5 = mne.read_epochs(epoch_path_5, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_1_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "8103 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_1_epo-1.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "8103 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "16206 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_2_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "8403 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_2_epo-1.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "8403 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "16806 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_3_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "15132 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "15132 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_4_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "8385 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_4_epo-1.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "8385 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "16770 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_5_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "15087 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "15087 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epoch1 = mne.read_epochs(epoch_path_1)\n",
    "epoch2 = mne.read_epochs(epoch_path_2)\n",
    "epoch3 = mne.read_epochs(epoch_path_3)\n",
    "epoch4 = mne.read_epochs(epoch_path_4)\n",
    "epoch5 = mne.read_epochs(epoch_path_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to Memory limitation, we're using the large epoch files 1-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48144 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epoch = mne.epochs.concatenate_epochs([epoch1, epoch2, epoch3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs  |   48144 events (all good), 0 - 0.5 sec, baseline [0, 0], ~11.52 GB, data loaded,\n",
       " 'AALL': 4380\n",
       " 'AALN': 4218\n",
       " 'AANL': 4248\n",
       " 'AANN': 3918\n",
       " 'AVLL': 3795\n",
       " 'AVNN': 4119\n",
       " 'VALL': 3795\n",
       " 'VANN': 4224\n",
       " 'VVLL': 3381\n",
       " 'VVLN': 4308\n",
       " 'VVNL': 3744\n",
       " 'VVNN': 4014>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch.drop_channels(['Lm', 'Rm', 'Nasium', 'VEOG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs  |   48144 events (all good), 0 - 0.5 sec, baseline [0, 0], ~11.34 GB, data loaded,\n",
       " 'AALL': 4380\n",
       " 'AALN': 4218\n",
       " 'AANL': 4248\n",
       " 'AANN': 3918\n",
       " 'AVLL': 3795\n",
       " 'AVNN': 4119\n",
       " 'VALL': 3795\n",
       " 'VANN': 4224\n",
       " 'VVLL': 3381\n",
       " 'VVLN': 4308\n",
       " 'VVNL': 3744\n",
       " 'VVNN': 4014>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing channels 'LL4', 'L12'\n",
    "epoch.drop_channels(['LL4', 'L12'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 : Audio vs. Visual, SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### epoch object has been updated with events that can be used for classification\n",
    "# epoch.events[:,-1] < 700 = audio  \n",
    "# epoch.events[:,-1] > 700 = visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a labels array\n",
    "# let 0 = audio, 1 = visual\n",
    "\n",
    "labels = [0 if (x < 700) else 1 for x in epoch.events[:,-1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
