{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Presentation Notebook\n",
    "By: Shateesh Bhugwansing\n",
    "### Perform my classification experiments from the semester on the entire data set\n",
    "\n",
    "Classifier: ~~Linear SVM~~ Logistic Regression\n",
    "1. Audio vs. Visual\n",
    "2. Language vs. Non language\n",
    "\n",
    "##### NOTE: Run this on the CCNY Computing Node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emmanuil converted the data into larger, 2GB chunks that we can use at a time. \n",
    "\n",
    "epoch_path_1 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_1_epo.fif' \n",
    "epoch_path_2 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_2_epo.fif'\n",
    "epoch_path_3 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_3_epo.fif'\n",
    "epoch_path_4 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_4_epo.fif'\n",
    "epoch_path_5 = '/home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_5_epo.fif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_path = [epoch_path_1, epoch_path_2, epoch_path_3, epoch_path_4, epoch_path_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch1 = mne.read_epochs(epoch_path_1, preload=True)\n",
    "# epoch2 = mne.read_epochs(epoch_path_2, preload=True)\n",
    "# epoch3 = mne.read_epochs(epoch_path_3, preload=True)\n",
    "# epoch4 = mne.read_epochs(epoch_path_4, preload=True)\n",
    "# epoch5 = mne.read_epochs(epoch_path_5, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch1 = mne.read_epochs(epoch_path_1)\n",
    "# epoch2 = mne.read_epochs(epoch_path_2)\n",
    "# epoch3 = mne.read_epochs(epoch_path_3)\n",
    "# epoch4 = mne.read_epochs(epoch_path_4)\n",
    "# epoch5 = mne.read_epochs(epoch_path_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch1 = mne.read_epochs(epoch_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch2 = mne.read_epochs(epoch_path_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/eproj/scratch/LARGE_EPOCH_OBJECTS/large_epoch_3_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "15132 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "15132 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epoch3 = mne.read_epochs(epoch_path_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = mne.epochs.concatenate_epochs([epoch1, epoch2, epoch3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch1.drop_channels(['LL4', 'L12','Nasium', 'VEOG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch2.drop_channels(['LL4', 'L12','Nasium', 'VEOG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EpochsFIF  |   15132 events (all good), 0 - 0.5 sec, baseline [0, 0], ~3.62 GB, data loaded,\n",
       " 'AALL': 1377\n",
       " 'AALN': 1251\n",
       " 'AANL': 1422\n",
       " 'AANN': 1077\n",
       " 'AVLL': 1197\n",
       " 'AVNN': 1134\n",
       " 'VALL': 1131\n",
       " 'VANN': 1491\n",
       " 'VVLL': 1248\n",
       " 'VVLN': 1134\n",
       " 'VVNL': 1419\n",
       " 'VVNN': 1251>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch3.drop_channels(['LL4', 'L12','Nasium', 'VEOG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing channels 'LL4', 'L12'\n",
    "# epoch.drop_channels(['LL4', 'L12'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 : Audio vs. Visual, Logistic Regression\n",
    "Using MNE Sliding estimator  \n",
    "example found here : https://mne-tools.github.io/0.16/auto_tutorials/plot_sensors_decoding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### epoch object has been updated with events that can be used for classification\n",
    "# epoch.events[:,-1] < 700 = audio  \n",
    "# epoch.events[:,-1] > 700 = visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a labels array\n",
    "# let 0 = audio, 1 = visual\n",
    "\n",
    "labels = [0 if (x < 700) else 1 for x in epoch1.events[:,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_np = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imports used for classification algos \n",
    "\n",
    "from mne.decoding import Vectorizer, get_coef\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = epoch1.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', max_iter=5000))\n",
    "\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "\n",
    "scores = cross_val_multiscore(time_decod, data, labels_np, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores = np.mean(scores, axis=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epoch1.times, scores, label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Sensor space decoding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can retrieve the spatial filters and spatial patterns if you explicitly\n",
    "# use a LinearModel\n",
    "clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression(solver='lbfgs', max_iter=5000)))\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "time_decod.fit(data, labels_np)\n",
    "\n",
    "\n",
    "coef = get_coef(time_decod, 'patterns_', inverse_transform=True)\n",
    "evoked = mne.EvokedArray(coef, epoch1.info, tmin=epoch1.times[0])\n",
    "joint_kwargs = dict(ts_args=dict(time_unit='s'),\n",
    "                    topomap_args=dict(time_unit='s'))\n",
    "evoked.plot_joint(title='patterns',\n",
    "                  **joint_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Language vs. Non Language, Logistic Regression \n",
    "Using MNE Sliding Estimator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = [112, 312, 512, 712, 912, 1112]\n",
    "non_language = [212, 412, 612, 812, 1012, 1212]\n",
    "\n",
    "labels2 = [0 if (x in language) else 1 for x in epoch2.events[:,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2_np = np.array(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 = epoch2.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = epoch3.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', max_iter=1000))\n",
    "\n",
    "time_decod2 = SlidingEstimator(clf2, n_jobs=1, scoring='roc_auc')\n",
    "\n",
    "scores2 = cross_val_multiscore(time_decod2, data2, labels2_np, cv=5, n_jobs=1)\n",
    "\n",
    "# Mean scores across cross-validation splits\n",
    "scores2 = np.mean(scores2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epoch2.times, scores2, label='score')\n",
    "ax.axhline(.5, color='k', linestyle='--', label='chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.axvline(.0, color='k', linestyle='-')\n",
    "ax.set_title('Sensor space decoding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can retrieve the spatial filters and spatial patterns if you explicitly\n",
    "# use a LinearModel\n",
    "clf = make_pipeline(StandardScaler(), LinearModel(LogisticRegression(solver='lbfgs', max_iter=5000)))\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "time_decod.fit(data2, labels2_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = get_coef(time_decod, 'patterns_', inverse_transform=True)\n",
    "evoked = mne.EvokedArray(coef, epoch2.info, tmin=epoch2.times[0])\n",
    "joint_kwargs = dict(ts_args=dict(time_unit='s'),\n",
    "                    topomap_args=dict(time_unit='s'))\n",
    "evoked.plot_joint(title='patterns',\n",
    "                  **joint_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch2.plot_psd_topomap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
