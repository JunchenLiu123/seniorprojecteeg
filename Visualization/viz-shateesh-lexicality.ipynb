{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicality: Language vs Non-Language\n",
    "A notebook to visualize the classification results of the lexicality problem\n",
    "\n",
    "Author: Shateesh Bhugwansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.read_montage(kind=\"ANT_DukeWaveGuard_128_electrode_montages_updated_V4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Volumes/SB/NEW_EPOCH_DATA/20140205_1114_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1908 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "1908 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# read in data \n",
    "epoch_path = '/Volumes/SB/NEW_EPOCH_DATA/20140205_1114_epo.fif'\n",
    "epoch = mne.read_epochs(epoch_path, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EpochsFIF  |   1908 events (all good), 0 - 0.5 sec, baseline [0, 0], ~467.9 MB, data loaded,\n",
       " 'b-f1-pic': 60\n",
       " 'b-f1-snd': 60\n",
       " 'b-f1-spk': 100\n",
       " 'b-f1-wrd': 79\n",
       " 'b-f2-pic': 60\n",
       " 'b-f2-snd': 60\n",
       " 'b-f2-spk': 100\n",
       " 'b-f2-wrd': 79\n",
       " 'b-tg-pic': 60\n",
       " 'b-tg-snd': 80\n",
       " 'b-tg-spk': 79\n",
       " 'b-tg-wrd': 80\n",
       " 'f-f1-pic': 100\n",
       " 'f-f1-snd': 59\n",
       " 'f-f1-spk': 99\n",
       " 'f-f1-wrd': 79\n",
       " 'f-f2-pic': 100\n",
       " 'f-f2-snd': 59\n",
       " 'f-f2-spk': 99\n",
       " 'f-f2-wrd': 79\n",
       " 'f-tg-pic': 99\n",
       " 'f-tg-snd': 99\n",
       " 'f-tg-spk': 79\n",
       " 'f-tg-wrd': 60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch.drop_channels(['Lm', 'Rm', 'Nasium', 'VEOG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EpochsFIF  |   1908 events (all good), 0 - 0.5 sec, baseline [0, 0], ~460.5 MB, data loaded,\n",
       " 'b-f1-pic': 60\n",
       " 'b-f1-snd': 60\n",
       " 'b-f1-spk': 100\n",
       " 'b-f1-wrd': 79\n",
       " 'b-f2-pic': 60\n",
       " 'b-f2-snd': 60\n",
       " 'b-f2-spk': 100\n",
       " 'b-f2-wrd': 79\n",
       " 'b-tg-pic': 60\n",
       " 'b-tg-snd': 80\n",
       " 'b-tg-spk': 79\n",
       " 'b-tg-wrd': 80\n",
       " 'f-f1-pic': 100\n",
       " 'f-f1-snd': 59\n",
       " 'f-f1-spk': 99\n",
       " 'f-f1-wrd': 79\n",
       " 'f-f2-pic': 100\n",
       " 'f-f2-snd': 59\n",
       " 'f-f2-spk': 99\n",
       " 'f-f2-wrd': 79\n",
       " 'f-tg-pic': 99\n",
       " 'f-tg-snd': 99\n",
       " 'f-tg-spk': 79\n",
       " 'f-tg-wrd': 60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing channels 'LL4', 'L12'\n",
    "epoch.drop_channels(['LL4', 'L12'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epoch.ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification experiment (to generate coefficients)\n",
    "Language vs. Non-Language  \n",
    "data: NEW_EPOCH_DATA/20140205_1114_epo.fif  \n",
    "classifier: Logistic regression  \n",
    "Labels:\n",
    "* 0 = Language\n",
    "* 1 = Non Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'preprocecssing_helpers.ipynb.py'` not found.\n",
      "ERROR:root:File `'Batch_ArtifactFilter_Epoch.ipynb.py'` not found.\n",
      "ERROR:root:File `'preprocecssing_helpers.ipynb.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "# Run Emmanuil's helper notebooks to re-label the data \n",
    "%run ../preprocessing/Artifact_Removal/Extract_Describer_Events.ipynb\n",
    "%run ../preprocessing/Artifact_Removal/preprocecssing_helpers.ipynb\n",
    "%run ../preprocessing/Artifact_Removal/Batch_ArtifactFilter_Epoch.ipynb\n",
    "%run ../preprocessing/StimCodes.ipynb\n",
    "%run ../Classification/ConcatEpochTrails.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AALL': 112,\n",
       " 'AALN': 212,\n",
       " 'AANL': 312,\n",
       " 'AANN': 412,\n",
       " 'AVLL': 512,\n",
       " 'AVNN': 612,\n",
       " 'VALL': 712,\n",
       " 'VANN': 812,\n",
       " 'VVLL': 912,\n",
       " 'VVLN': 1012,\n",
       " 'VVNL': 1112,\n",
       " 'VVNN': 1212}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modality_lexicality_event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_event_ids = convert_epoch_events_to_stim_combinations(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.events = new_event_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epoch object has been updated with events that can be used for classification\n",
    "epoch.events[:,-1] in {112, 312, 512, 712, 912, 1112} = Language  \n",
    "epoch.events[:,-1] in {212, 412, 612, 812, 1012, 1212} = Non Language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = [112, 312, 512, 712, 912, 1112]\n",
    "non_language = [212, 412, 612, 812, 1012, 1212]\n",
    "\n",
    "labels = [0 if (x in language) else 1 for x in epoch.events[:,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_np = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imports used for classification algos \n",
    "\n",
    "from mne.decoding import Vectorizer, get_coef\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform logistic regression, use cross validation\n",
    "\n",
    "clf = make_pipeline(\n",
    "                    Vectorizer(),\n",
    "#                     MinMaxScaler(),\n",
    "                    LogisticRegression(C=1))\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.empty(len(epoch._data))\n",
    "coeff = []\n",
    "data = epoch._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = epoch._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Language       0.65      0.67      0.66      1071\n",
      "Non-Language       0.56      0.54      0.55       837\n",
      "\n",
      " avg / total       0.61      0.62      0.61      1908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train, test in cv.split(data, labels_np):\n",
    "    clf.fit(data[train], labels_np[train])\n",
    "    coeff.append(get_coef(clf,'coef_'))\n",
    "    preds[test] = clf.predict(data[test])\n",
    "    \n",
    "target_names = [ 'Language', 'Non-Language']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, data, labels, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.734375  , 0.47120419, 0.64921466, 0.78534031, 0.32984293,\n",
       "       0.52879581, 0.66492147, 0.33157895, 0.85789474, 0.61578947])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_coeff_matrix(x, step):\n",
    "    \"\"\"\n",
    "    A method to reshape a 1D list of coefficients into the coefficient matrix: \n",
    "    example: (1, 615000) --> (123, 500)\n",
    "    \n",
    "    NOTE: YOU NEED TO IMPORT numpy as np to use this method\n",
    "    \n",
    "    Arguments: \n",
    "    - x = the current, 1D list of coefficients that needs to be reshaped. \n",
    "    - step = the desired length of one row in the new matrix (default = 500)\n",
    "    \n",
    "    Return:\n",
    "    - A 2D np array with the desired shape\n",
    "    \"\"\"\n",
    "    reshaped = []\n",
    "    \n",
    "    for i in range(0,len(x), step): \n",
    "        temp = []\n",
    "        for j in range(i,i+step):\n",
    "            temp.append(x[j])\n",
    "    \n",
    "        reshaped.append(temp)\n",
    "    \n",
    "    return np.array(reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31611"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coeff[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1908, 123, 257)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper function to reshape all of the coefficients in coeff\n",
    "# use the step = 257, want each coefficient matrix in the shape 123x257\n",
    "coeff_matrices = []\n",
    "\n",
    "for i in coeff:\n",
    "    coeff_matrices.append(reshape_coeff_matrix(i[0], 257))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking the channel + coefficients \n",
    "- To do this, I'm going to rank the channels based on the mean of their coefficients over the 500ms period. \n",
    "- Do this for each ofthe 10 coefficient matricies that are produced. \n",
    "- The hypothesis is that the same channels should appear at the top, meaning they are the same channels being used to do the classification every time (highest coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_matrices_mean = []\n",
    "\n",
    "for x in coeff_matrices:\n",
    "    avg = []\n",
    "    for i in range(len(x)):\n",
    "        avg.append(np.mean(x[i]))\n",
    "    coeff_matrices_mean.append(avg)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_matrices_mean_np = np.array(coeff_matrices_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 123)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_matrices_mean_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = epoch.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the means to the channels\n",
    "\n",
    "coeff_means_channels = []\n",
    "\n",
    "for x in range(len(coeff_matrices_mean_np)):\n",
    "    coeff_means_channels.append(dict(zip(channels, coeff_matrices_mean_np[x])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LE1': 0.00012212852027751337,\n",
       " 'LE3': 1.9579086675459683e-05,\n",
       " 'LD2': 0.00011389380116126542,\n",
       " 'LD5': 0.00010714624331361098,\n",
       " 'LC3': 9.893853819879851e-05,\n",
       " 'LC6': 3.8849552206186846e-06,\n",
       " 'LB1': 0.00011471711621153446,\n",
       " 'LB4': 4.004214053368584e-05,\n",
       " 'LA2': 6.538288074623115e-05,\n",
       " 'LA5': -4.5510189763097396e-05,\n",
       " 'LL1': 0.00011593351028269707,\n",
       " 'LL7': -4.1757924246961456e-05,\n",
       " 'LL10': -3.045425314232178e-05,\n",
       " 'LL13': -0.00012720579135966473,\n",
       " 'L3': 7.896946904082052e-05,\n",
       " 'L6': 5.604365091816641e-05,\n",
       " 'L9': -4.182736895891435e-05,\n",
       " 'Z1': 0.00011076770982227248,\n",
       " 'Z4': 5.872504693504361e-05,\n",
       " 'Z7': -4.800917534941003e-06,\n",
       " 'Z10': -0.0001084390973810687,\n",
       " 'Z13': -0.00011885085801885782,\n",
       " 'R3': 6.66301855104364e-05,\n",
       " 'R6': 1.7482183472743217e-05,\n",
       " 'R9': -4.6162541097757884e-05,\n",
       " 'R12': -0.00013681249530368892,\n",
       " 'RR1': 6.483566281728567e-05,\n",
       " 'RR4': 4.695825814991631e-06,\n",
       " 'RR7': 2.4257038458082003e-05,\n",
       " 'RR10': -7.823409830967416e-05,\n",
       " 'RR13': -0.00014062573880353974,\n",
       " 'RA2': 1.9230525328984673e-05,\n",
       " 'RA5': -7.391848476922196e-05,\n",
       " 'RB1': 3.081021227897923e-05,\n",
       " 'RB4': -3.0003826284658717e-05,\n",
       " 'RC3': 7.545532669395641e-06,\n",
       " 'RC6': -0.00011318734472752274,\n",
       " 'RD2': 4.352810580918729e-05,\n",
       " 'RD5': -6.993681843300093e-05,\n",
       " 'RE1': 6.218297911291529e-05,\n",
       " 'RE3': -4.0848505440554664e-05,\n",
       " 'RE4': -3.9456457221519844e-05,\n",
       " 'RD1': 3.436702444878068e-05,\n",
       " 'RD3': -4.925007818264643e-06,\n",
       " 'RD4': -3.340291020176227e-06,\n",
       " 'RD6': -0.00010650522446201241,\n",
       " 'RD7': -0.00012473638868470586,\n",
       " 'RC1': 3.742896508322555e-05,\n",
       " 'RC2': 2.863495649351277e-06,\n",
       " 'RC4': -7.207839769254144e-07,\n",
       " 'RC5': -3.533753123399464e-05,\n",
       " 'RC7': -9.544113846831368e-05,\n",
       " 'RB2': 5.5050295910238475e-06,\n",
       " 'RB3': 1.011612803426802e-05,\n",
       " 'RB5': -8.612123389129084e-05,\n",
       " 'RB6': -7.206299731696902e-05,\n",
       " 'RA1': 3.181640273861991e-05,\n",
       " 'RA3': 2.4435445085769473e-06,\n",
       " 'RA4': -3.741540395002817e-05,\n",
       " 'RR2': 3.38673823019292e-05,\n",
       " 'RR3': 2.961088951140109e-05,\n",
       " 'RR5': 5.343299226950991e-05,\n",
       " 'RR6': -1.9771742533038498e-06,\n",
       " 'RR8': -9.676587968032348e-06,\n",
       " 'RR9': -5.702249061469558e-05,\n",
       " 'RR11': -0.00015470205825623352,\n",
       " 'RR12': -0.0001473373503056227,\n",
       " 'R1': 0.00010759816463035997,\n",
       " 'R2': 8.637411705886755e-05,\n",
       " 'R4': 4.194112606930288e-05,\n",
       " 'R5': 2.2090673745221265e-05,\n",
       " 'R7': 3.011939062312426e-05,\n",
       " 'R8': 1.410252689258949e-06,\n",
       " 'R10': -8.68048878498589e-05,\n",
       " 'R11': -0.00012183085716345255,\n",
       " 'R13': -0.0001369017590018683,\n",
       " 'R14': -0.00013713194362626255,\n",
       " 'Z2': 7.274956689297839e-05,\n",
       " 'Z3': 4.927898983429061e-05,\n",
       " 'Z5': 4.89283114476106e-05,\n",
       " 'Z6': 2.1404153796699582e-05,\n",
       " 'Z8': -3.9729747705720464e-05,\n",
       " 'Z9': -6.933957599509358e-05,\n",
       " 'Z11': -9.981654052594342e-05,\n",
       " 'Z12': -0.00010493760346105271,\n",
       " 'Z14': -0.000135037205093493,\n",
       " 'L1': 0.00011910390654237886,\n",
       " 'L2': 0.00010722151628033105,\n",
       " 'L4': 5.612191293724614e-05,\n",
       " 'L5': 6.633660669553753e-05,\n",
       " 'L7': 3.202556362351834e-05,\n",
       " 'L8': -2.998032454651746e-05,\n",
       " 'L10': -4.375647313117231e-05,\n",
       " 'L11': -0.0001127648798869848,\n",
       " 'L13': -0.00013700565942136386,\n",
       " 'L14': -8.939086178219194e-05,\n",
       " 'LL2': 0.00011694346369008895,\n",
       " 'LL3': 9.260197394130021e-05,\n",
       " 'LL5': 6.0207226784549495e-05,\n",
       " 'LL6': 3.264186834341428e-05,\n",
       " 'LL8': -3.9029282044024375e-05,\n",
       " 'LL9': -2.190602690079949e-05,\n",
       " 'LL11': -4.5677662111166055e-05,\n",
       " 'LL12': -0.00013980154675547157,\n",
       " 'LA1': 7.998185183751237e-05,\n",
       " 'LA3': 2.146626341897551e-05,\n",
       " 'LA4': 3.636066987933803e-05,\n",
       " 'LB2': 0.00010763254538787995,\n",
       " 'LB3': 6.8931203294885e-05,\n",
       " 'LB5': -5.6100066480134835e-05,\n",
       " 'LB6': -4.353886178560381e-05,\n",
       " 'LC1': 0.00013039768642167157,\n",
       " 'LC2': 0.00011417668118912976,\n",
       " 'LC4': 6.062865522804625e-05,\n",
       " 'LC5': 3.233847597974839e-05,\n",
       " 'LC7': -5.44223703293762e-05,\n",
       " 'LD1': 0.0001662079870516679,\n",
       " 'LD3': 0.00010125924505984796,\n",
       " 'LD4': 0.00011261109785866801,\n",
       " 'LD6': -1.5721977086493536e-05,\n",
       " 'LD7': -5.300381604096893e-05,\n",
       " 'LE4': -0.00011601166393927418,\n",
       " 'STI 014': 0.0019732576832445434}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_means_channels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all mean coefficients to abs value \n",
    "\n",
    "for d in coeff_means_channels:\n",
    "    for k in d: \n",
    "        d[k] = abs(d[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort each dictionary in coeff_means_channels in order to rank them. should expect to see the same channels at the top\n",
    "# for each dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_means_channels = []\n",
    "\n",
    "for x in range(len(coeff_means_channels)):\n",
    "    d = coeff_means_channels[x]\n",
    "    sorted_means_channels.append(sorted(d, key=d.get, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STI 014',\n",
       " 'LD1',\n",
       " 'RR11',\n",
       " 'RR12',\n",
       " 'RR13',\n",
       " 'LL12',\n",
       " 'R14',\n",
       " 'L13',\n",
       " 'R13',\n",
       " 'R12',\n",
       " 'Z14',\n",
       " 'LC1',\n",
       " 'LL13',\n",
       " 'RD7',\n",
       " 'LE1',\n",
       " 'R11',\n",
       " 'L1',\n",
       " 'Z13',\n",
       " 'LL2',\n",
       " 'LE4',\n",
       " 'LL1',\n",
       " 'LB1',\n",
       " 'LC2',\n",
       " 'LD2',\n",
       " 'RC6',\n",
       " 'L11',\n",
       " 'LD4',\n",
       " 'Z1',\n",
       " 'Z10',\n",
       " 'LB2',\n",
       " 'R1',\n",
       " 'L2',\n",
       " 'LD5',\n",
       " 'RD6',\n",
       " 'Z12',\n",
       " 'LD3',\n",
       " 'Z11',\n",
       " 'LC3',\n",
       " 'RC7',\n",
       " 'LL3',\n",
       " 'L14',\n",
       " 'R10',\n",
       " 'R2',\n",
       " 'RB5',\n",
       " 'LA1',\n",
       " 'L3',\n",
       " 'RR10',\n",
       " 'RA5',\n",
       " 'Z2',\n",
       " 'RB6',\n",
       " 'RD5',\n",
       " 'Z9',\n",
       " 'LB3',\n",
       " 'R3',\n",
       " 'L5',\n",
       " 'LA2',\n",
       " 'RR1',\n",
       " 'RE1',\n",
       " 'LC4',\n",
       " 'LL5',\n",
       " 'Z4',\n",
       " 'RR9',\n",
       " 'L4',\n",
       " 'LB5',\n",
       " 'L6',\n",
       " 'LC7',\n",
       " 'RR5',\n",
       " 'LD7',\n",
       " 'Z3',\n",
       " 'Z5',\n",
       " 'R9',\n",
       " 'LL11',\n",
       " 'LA5',\n",
       " 'L10',\n",
       " 'LB6',\n",
       " 'RD2',\n",
       " 'R4',\n",
       " 'L9',\n",
       " 'LL7',\n",
       " 'RE3',\n",
       " 'LB4',\n",
       " 'Z8',\n",
       " 'RE4',\n",
       " 'LL8',\n",
       " 'RC1',\n",
       " 'RA4',\n",
       " 'LA4',\n",
       " 'RC5',\n",
       " 'RD1',\n",
       " 'RR2',\n",
       " 'LL6',\n",
       " 'LC5',\n",
       " 'L7',\n",
       " 'RA1',\n",
       " 'RB1',\n",
       " 'LL10',\n",
       " 'R7',\n",
       " 'RB4',\n",
       " 'L8',\n",
       " 'RR3',\n",
       " 'RR7',\n",
       " 'R5',\n",
       " 'LL9',\n",
       " 'LA3',\n",
       " 'Z6',\n",
       " 'LE3',\n",
       " 'RA2',\n",
       " 'R6',\n",
       " 'LD6',\n",
       " 'RB3',\n",
       " 'RR8',\n",
       " 'RC3',\n",
       " 'RB2',\n",
       " 'RD3',\n",
       " 'Z7',\n",
       " 'RR4',\n",
       " 'LC6',\n",
       " 'RD4',\n",
       " 'RC2',\n",
       " 'RA3',\n",
       " 'RR6',\n",
       " 'R8',\n",
       " 'RC4']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_means_channels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STI 014',\n",
       " 'RR12',\n",
       " 'RR13',\n",
       " 'RD7',\n",
       " 'RC6',\n",
       " 'RD6',\n",
       " 'R11',\n",
       " 'RC7',\n",
       " 'RR11',\n",
       " 'LE1',\n",
       " 'LD2',\n",
       " 'RB5',\n",
       " 'R1',\n",
       " 'Z14',\n",
       " 'LL12',\n",
       " 'R14',\n",
       " 'LD4',\n",
       " 'L13',\n",
       " 'R13',\n",
       " 'R12',\n",
       " 'LL13',\n",
       " 'LD5',\n",
       " 'R2',\n",
       " 'LC3',\n",
       " 'RD5',\n",
       " 'RR10',\n",
       " 'LB2',\n",
       " 'LD1',\n",
       " 'Z10',\n",
       " 'L11',\n",
       " 'LD3',\n",
       " 'Z12',\n",
       " 'RR1',\n",
       " 'LB3',\n",
       " 'Z13',\n",
       " 'RA5',\n",
       " 'RB6',\n",
       " 'LE4',\n",
       " 'R10',\n",
       " 'Z1',\n",
       " 'L1',\n",
       " 'LC4',\n",
       " 'Z11',\n",
       " 'RE3',\n",
       " 'LB4',\n",
       " 'LB1',\n",
       " 'LC2',\n",
       " 'RC5',\n",
       " 'L2',\n",
       " 'LC1',\n",
       " 'LA4',\n",
       " 'LL5',\n",
       " 'RD1',\n",
       " 'LL2',\n",
       " 'R3',\n",
       " 'RE1',\n",
       " 'LA2',\n",
       " 'RR9',\n",
       " 'LC5',\n",
       " 'RC1',\n",
       " 'LL1',\n",
       " 'LA1',\n",
       " 'L5',\n",
       " 'LA3',\n",
       " 'RA4',\n",
       " 'LC6',\n",
       " 'Z9',\n",
       " 'RD2',\n",
       " 'RB1',\n",
       " 'L3',\n",
       " 'Z2',\n",
       " 'RR5',\n",
       " 'LL6',\n",
       " 'L6',\n",
       " 'LL3',\n",
       " 'R9',\n",
       " 'RR2',\n",
       " 'L7',\n",
       " 'Z4',\n",
       " 'RB4',\n",
       " 'R7',\n",
       " 'RR3',\n",
       " 'Z5',\n",
       " 'L4',\n",
       " 'LE3',\n",
       " 'Z3',\n",
       " 'RA1',\n",
       " 'Z6',\n",
       " 'R4',\n",
       " 'Z8',\n",
       " 'L14',\n",
       " 'R6',\n",
       " 'R5',\n",
       " 'RR8',\n",
       " 'RD3',\n",
       " 'LL7',\n",
       " 'RA3',\n",
       " 'RD4',\n",
       " 'RA2',\n",
       " 'LD6',\n",
       " 'RC2',\n",
       " 'RC4',\n",
       " 'LB6',\n",
       " 'LL9',\n",
       " 'RR7',\n",
       " 'R8',\n",
       " 'L9',\n",
       " 'RE4',\n",
       " 'RB2',\n",
       " 'Z7',\n",
       " 'LL8',\n",
       " 'RC3',\n",
       " 'LL11',\n",
       " 'RR6',\n",
       " 'L10',\n",
       " 'RR4',\n",
       " 'LA5',\n",
       " 'LB5',\n",
       " 'LD7',\n",
       " 'L8',\n",
       " 'RB3',\n",
       " 'LC7',\n",
       " 'LL10']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_means_channels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the top 30 ranking channels, based on their mean coefficients, from all 10 iterations of the classification.\n",
    "# Are the top 30 the same across all 10 iterations?\n",
    "# note: I took the top 30, because 30 is roughly 25% of 123\n",
    "\n",
    "top20 = []\n",
    "\n",
    "for x in sorted_means_channels:\n",
    "    top20.append(x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_np = np.array(top20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_flat = top20_np.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(top20_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'STI 014': 10,\n",
       "         'LD1': 9,\n",
       "         'RR11': 10,\n",
       "         'RR12': 10,\n",
       "         'RR13': 10,\n",
       "         'LL12': 9,\n",
       "         'R14': 9,\n",
       "         'L13': 8,\n",
       "         'R13': 8,\n",
       "         'R12': 9,\n",
       "         'Z14': 9,\n",
       "         'LC1': 2,\n",
       "         'LL13': 7,\n",
       "         'RD7': 10,\n",
       "         'LE1': 5,\n",
       "         'R11': 9,\n",
       "         'L1': 2,\n",
       "         'Z13': 4,\n",
       "         'LL2': 2,\n",
       "         'LE4': 3,\n",
       "         'RC6': 9,\n",
       "         'RD6': 9,\n",
       "         'RC7': 8,\n",
       "         'LD2': 4,\n",
       "         'RB5': 4,\n",
       "         'R1': 6,\n",
       "         'LD4': 3,\n",
       "         'L14': 1,\n",
       "         'R2': 2,\n",
       "         'Z1': 4,\n",
       "         'LE3': 1,\n",
       "         'Z10': 1,\n",
       "         'L2': 1,\n",
       "         'LL1': 1,\n",
       "         'RR10': 1})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.pop('STI 014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
