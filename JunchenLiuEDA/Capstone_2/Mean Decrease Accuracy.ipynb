{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use MDA(mean decrease accuracy) to select features\n",
    "* this notebook will use MDA(mean decrease accuracy) on random forest to select the features that contributes the most to classfication scores.\n",
    "* The goal is to be able to do feature selection and find the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mne.decoding import SPoC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE \n",
    "import os\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "import os.path as op\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "from scipy.stats import skew, kurtosis\n",
    "import mne \n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from urllib.request import urlopen\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'.../preprocessing/Artifact_Removal/preprocecssing_helpers.ipynb.py'` not found.\n",
      "ERROR:root:File `'../preprocessing/StimCodes.ipynb.py'` not found.\n",
      "ERROR:root:File `'../preprocessing/Artifact_Removal/preprocecssing_helpers.ipynb.py'` not found.\n",
      "ERROR:root:File `'../preprocessing/StimCodes.ipynb.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run Batch_ArtifactFilter_Epoch.ipynb\n",
    "\n",
    "%run .../preprocessing/Artifact_Removal/preprocecssing_helpers.ipynb\n",
    "%run ../../preprocessing/Artifact_Removal/Extract_Describer_Events.ipynb\n",
    "%run ../../preprocessing/StimCodes.ipynb\n",
    "%run ../../Classification/ConcatEpochTrails.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\USB Drive\\NewEEG-200s\\New\\20131216_1310_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1759 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "1759 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epoch=mne.read_epochs('D:\\\\USB Drive\\\\NewEEG-200s\\\\New\\\\20131216_1310_epo.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Methods for convert our events into binary, 4: Language, 5:Non Language\n",
    "def filter_event_id(epoch):\n",
    "    newepoch=epoch\n",
    "    epochs=[[]]\n",
    "    j=0\n",
    "    for i in range(len(newepoch.events[:,-1])):\n",
    "        if i % 3 ==0:\n",
    "            epochs.append([])\n",
    "            j=j+1\n",
    "            epochs[j].append(epoch.events[i,-1])\n",
    "        else:\n",
    "            epochs[j].append(epoch.events[i,-1])\n",
    "    for events in epochs:\n",
    "        if  4 in events or 1 in events or 13 in events or 16 in events:\n",
    "            for i in range(len(events)):\n",
    "                    events[i]=5\n",
    "        else:\n",
    "            for i in range(len(events)):\n",
    "                    events[i]=4\n",
    "    epochs.pop(0)\n",
    "    flattened_list = [y for x in epochs for y in x]\n",
    "    for i in range(len(newepoch.events)):\n",
    "        newepoch.events[i]=flattened_list[i]\n",
    "    return newepoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "epoch=filter_event_id(epoch)\n",
    "print(epoch.events[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Bad Channels\n",
    "if 'Nasium' in epoch.ch_names:\n",
    "    epoch.drop_channels(ch_names=['Nasium', 'LL4', 'L12', 'VEOG','STI 014']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vecorized 3d to 2d\n",
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape,epoch.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingsly\\Anaconda3\\envs\\mne\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5549242424242424\n"
     ]
    }
   ],
   "source": [
    "## Logisticalregression classfier\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                   StandardScaler(),\n",
    "                         LogisticRegression())\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_trials(epoch_object):\n",
    "    #note: third stim-code has a value that is 1 more than the first.\n",
    "    events = epoch_object.events\n",
    "    found_first_stim_code = False\n",
    "    found_second_stim_code = False\n",
    "    found_third_stim_code = False\n",
    "    current_trial = []\n",
    "    trials = []\n",
    "    for event in events:\n",
    "        if not found_first_stim_code and not found_second_stim_code and not found_third_stim_code: #still searching for the end of trial\n",
    "            current_trial.append(event)\n",
    "            found_first_stim_code = True\n",
    "            first_stim_code = event\n",
    "        elif not found_second_stim_code and not found_third_stim_code:\n",
    "            current_trial.append(event)\n",
    "            found_second_stim_code = True\n",
    "        elif not found_third_stim_code and (event[-1] + 1) == first_stim_code[-1]: \n",
    "            current_trial.append(event)\n",
    "            found_third_stim_code = True\n",
    "            trials.append(current_trial)\n",
    "            current_trial = []\n",
    "            found_first_stim_code = False\n",
    "            found_second_stim_code = False\n",
    "            found_third_stim_code = False\n",
    "        elif not found_third_stim_code and (event[-1] + 1) != first_stim_code[-1]:\n",
    "            # there is no third event, trial is unfinished.\n",
    "            current_trial = []\n",
    "            current_trial.append(event)#assuming it's first stim-code...for now\n",
    "            found_first_stim_code = True\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stim_code_combination_from_trial(stim_code_tuple, stim_combinations):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        returns the correct stim-code combination event id \n",
    "        example - a trial has events (20, 15, 19), this method will match those values to a \n",
    "        stim combination that is defined in the dictionary stim_combinations\n",
    "    \"\"\"\n",
    "    for stim_code in stim_combinations.keys():\n",
    "        if stim_code_tuple == stim_code:\n",
    "            return stim_combinations[stim_code]\n",
    "    return \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_epoch_events_to_stim_combinations(epoch_object):\n",
    "    trials = get_epoch_trials(epoch_object)\n",
    "    new_events_master = []\n",
    "    \n",
    "    for trial in trials:\n",
    "#         print(trial)\n",
    "        trial = np.array(trial)\n",
    "        stim_codes = trial[:,-1]\n",
    "        try:\n",
    "#             print(stim_codes)\n",
    "            stim_code_tuple = (stim_codes[0],stim_codes[1], stim_codes[2])\n",
    "#             print(stim_code_tuple)\n",
    "            stim_combination = stim_code_combination_from_trial(stim_code_tuple, stim_combinations)\n",
    "\n",
    "            new_event_id = modality_lexicality_event_ids[stim_combination]\n",
    "            trial[:,-1] = new_event_id\n",
    "            new_events_master.append(trial)\n",
    "        except:\n",
    "            print(\"Error with stim-code: {0}\".format(stim_codes))\n",
    "        \n",
    "    return np.concatenate([x for x in new_events_master])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with stim-code: [11 12]\n"
     ]
    }
   ],
   "source": [
    "new_events = convert_epoch_events_to_stim_combinations(epoch)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_combinations = {\n",
    "    (5,6,4): \"AALL\",\n",
    "    (17,18,16) :\"AALL\",\n",
    "    \n",
    "    (11,6,10):\"AALN\",\n",
    "    (23,18,22):\"AALN\",\n",
    "    \n",
    "    (5,12,4) :\"AANL\",\n",
    "    (17,24,16):\"AANL\",\n",
    "    \n",
    "    (11,12,10) : \"AANN\",\n",
    "    (23,24,22): \"AANN\",\n",
    "    \n",
    "    (2,6,1):\"AVLL\",\n",
    "    (14,18,13):\"AVLL\",\n",
    "    \n",
    "    (8,12,7):\"AVNN\",\n",
    "    (20,24,19):\"AVNN\",\n",
    "    \n",
    "    (5,3,4) :\"VALL\",\n",
    "    (17,15,16):\"VALL\",\n",
    "    \n",
    "    (11,9,10) :\"VANN\",\n",
    "    (23,21,22):\"VANN\",\n",
    "    \n",
    "    (2,3,1) :\"VVLL\",\n",
    "    (14,15,13):\"VVLL\",\n",
    "    \n",
    "    (8,3,7):\"VVLN\",\n",
    "    (20,15,19):\"VVLN\",\n",
    "    \n",
    "    (2,9,1) :\"VVNL\",\n",
    "    (14,21,13):\"VVNL\",\n",
    "    \n",
    "    (8,9,7) :\"VVNN\",\n",
    "    (20,21,19):\"VVNN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   464,      0,    512],\n",
       "       [   713,      0,    512],\n",
       "       [   972,      0,    512],\n",
       "       ...,\n",
       "       [614661,      0,    912],\n",
       "       [614920,      0,    912],\n",
       "       [614922,      0,    912]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_epoch = epoch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = copy_epoch.pick_types(meg=False, eeg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_epoch.events = new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_epoch.events[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1759, 31868)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape,epoch.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Nasium' in epoch.ch_names:\n",
    "    epoch.drop_channels(ch_names=['Nasium', 'LL4', 'L12', 'VEOG','STI 014']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1759, 124, 257) (1759, 124, 257)\n"
     ]
    }
   ],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "print(X.shape,epoch.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Mean Decrease Accuracy to select important features and fit the data.\n",
    "sel = SelectFromModel(\n",
    "    PermutationImportance(RandomForestRegressor(n_estimators =10, random_state = 42),cv=5),\n",
    "    threshold=0.05,\n",
    ").fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans = sel.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators =10, random_state = 42))\n",
    "time_decod = SlidingEstimator(clf, n_jobs=1, scoring='roc_auc')\n",
    "time_decod.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = time_decod.feature_importances\n",
    "evoked = mne.EvokedArray(coef, epochs.info, tmin=epochs.times[0])\n",
    "joint_kwargs = dict(ts_args=dict(time_unit='s'),\n",
    "                    topomap_args=dict(time_unit='s'))\n",
    "evoked.plot_joint(times=np.arange(0., .500, .100), title='patterns',\n",
    "                  **joint_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
