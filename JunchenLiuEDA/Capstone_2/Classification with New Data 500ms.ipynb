{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classfication with the correct formatted epoch of 500ms\n",
    "* this notebook will first label the epoch data events as 4: Language or 5 : nonlanguage. Then do classification on the labeled epoch data\n",
    "* The goal is to be able to classfy the correct data based on language vs. nonlanguage and see what kind of scores we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mne.decoding import SPoC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE \n",
    "import os\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "import os.path as op\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "from scipy.stats import skew, kurtosis\n",
    "import mne \n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Batch_ArtifactFilter_Epoch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=remove_artifacts_and_create_epochs('C:\\\\USB Drive\\\\NewEEG-200s\\\\SA20140205\\\\20140205_1230.set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Methods for dividing the events into trials with 3 events make up 1 trial\n",
    "epochs=[[]]\n",
    "j=0\n",
    "for i in range(len(epoch.events[:,-1])):\n",
    "    if i % 3 ==0:\n",
    "       \n",
    "        epochs.append([])\n",
    "        j=j+1\n",
    "        epochs[j].append(epoch.events[i,-1])\n",
    "              \n",
    "    else:\n",
    "        epochs[j].append(epoch.events[i,-1])\n",
    "        # Convert the epoch data into list of list\n",
    "        #Each list contains three event ids as 1 trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.events[2,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.events[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for events in epochs:\n",
    "    if  4 in events or 1 in events or 13 in events or 16 in events:\n",
    "        for i in range(len(events)):\n",
    "                events[i]=4\n",
    "    else:\n",
    "        for i in range(len(events)):\n",
    "                events[i]=5\n",
    "        # Label each trial as either Language or non-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put the labeled data back to the epoch event object\n",
    "epochs.pop(0)\n",
    "flattened_list = [y for x in epochs for y in x]\n",
    "for i in range(len(epoch.events)):\n",
    "    epoch.events[i]=flattened_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## knn classifier\n",
    "def classify_test_KNN(X,y):\n",
    "\n",
    "    clf = make_pipeline(Vectorizer(),\n",
    "                        StandardScaler(),\n",
    "                        KNN(n_neighbors=11))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    score = clf.score(X_test, y_test)\n",
    "    \n",
    "    return score\n",
    "epoch.events[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Methods for convert our events into binary, 4: Language, 5:Non Language\n",
    "def filter_event_id(epoch):\n",
    "    epochs=[[]]\n",
    "    j=0\n",
    "    for i in range(len(epoch.events[:,-1])):\n",
    "        if i % 3 ==0:\n",
    "            epochs.append([])\n",
    "            j=j+1\n",
    "            epochs[j].append(epoch.events[i,-1])\n",
    "        else:\n",
    "            epochs[j].append(epoch.events[i,-1])\n",
    "    for events in epochs:\n",
    "        if  4 in events or 1 in events or 13 in events or 16 in events:\n",
    "            for i in range(len(events)):\n",
    "                    events[i]=4\n",
    "        else:\n",
    "            for i in range(len(events)):\n",
    "                    events[i]=5\n",
    "    epochs.pop(0)\n",
    "    flattened_list = [y for x in epochs for y in x]\n",
    "    for i in range(len(epoch.events)):\n",
    "        epoch.events[i]=flattened_list[i]\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## methods for getting the target and features for our data\n",
    "def get_samples_targets(epochs):\n",
    "    X = epochs.get_data();\n",
    "    y = epochs.events[:,-1]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classfication with KNN\n",
    "X = epoch.get_data()\n",
    "y=epoch.events[:,-1]\n",
    "\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                        KNN(n_neighbors=13))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "score = clf.score(X_test, y_test)\n",
    "print (score)\n",
    "#classfication with KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\USB Drive\\\\NewEEG-200s'\n",
    "\n",
    "eeglab_files = os.listdir(path)\n",
    "eeglab_dict = search_folders(path, eeglab_files)\n",
    "eeglab_files = paths_of_eeglab_files(path, eeglab_dict)\n",
    "for f in eeglab_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = []\n",
    "\n",
    "path = 'C:\\\\USB Drive\\\\NewEEG-200s'\n",
    "## Run classfication with all the subject files in the path\n",
    "eeglab_files = os.listdir(path)\n",
    "eeglab_dict = search_folders(path, eeglab_files)\n",
    "eeglab_files = paths_of_eeglab_files(path, eeglab_dict)\n",
    "for f in eeglab_files:\n",
    "    epoch=remove_artifacts_and_create_epochs(f)\n",
    "    epoch = filter_event_id(epoch)\n",
    "    X,y = get_samples_targets(epoch)\n",
    "    scores1.append([f, classify_test_KNN(X,y)])\n",
    "    print(scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=remove_artifacts_and_create_epochs('C:\\\\USB Drive\\\\NewEEG-200s\\\\SA20131216\\\\20131216_1310.set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_event_id(epoch):\n",
    "    epochs=[[]]\n",
    "    j=0\n",
    "    for i in range(len(epoch.events[:,-1])):\n",
    "        if i % 3 ==0:\n",
    "            epochs.append([])\n",
    "            j=j+1\n",
    "            epochs[j].append(epoch.events[i,-1])\n",
    "        else:\n",
    "            epochs[j].append(epoch.events[i,-1])\n",
    "    for events in epochs:\n",
    "        if  4 in events or 1 in events or 13 in events or 16 in events:\n",
    "            for i in range(len(events)):\n",
    "                    events[i]=4\n",
    "        else:\n",
    "            for i in range(len(events)):\n",
    "                    events[i]=5\n",
    "    epochs.pop(0)\n",
    "    flattened_list = [y for x in epochs for y in x]\n",
    "    for i in range(len(epoch.events)):\n",
    "        epoch.events[i]=flattened_list[i]\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_event_id(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do PCA to reduce dimensions and data needed for classification.\n",
    "pca = UnsupervisedSpatialFilter(PCA(28), average=False) # PCA, keep 9 components \n",
    "\n",
    "epoch_data = epoch.get_data()\n",
    "pca_data = pca.fit_transform(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Kurtosis, vairance, skewness for our data\n",
    "def get_mean_band(data):\n",
    "    final_variances = []\n",
    "    for d in data:\n",
    "    #     print (data.shape)\n",
    "        variances = []\n",
    "        skewnesses = []\n",
    "        kurtosises = []\n",
    "        stats = []\n",
    "        for channel in d:\n",
    "    #         print(channel.shape)\n",
    "            var = channel.var()\n",
    "            variances.append(var)\n",
    "            \n",
    "            skewness = skew(channel, axis=0)\n",
    "#             print(skewness)\n",
    "\n",
    "            skewnesses.append(skewness)\n",
    "#             print(skewness)\n",
    "            kurt = kurtosis(channel)\n",
    "            kurtosises.append(kurt)\n",
    "#         print(skewnesses)\n",
    "#         mean_skew = np.mean(skewnesses)\n",
    "#         stats.append(mean_skew)\n",
    "#         stats.append(np.mean(variances))\n",
    "        final_variances.append([np.mean(variances), np.mean(skewnesses), np.mean(kurtosises)])\n",
    "    \n",
    "    return np.array(final_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_statisitcs = get_mean_band(pca_data)\n",
    "epoch.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_statisitcs.shape\n",
    "epoch.events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_statisitcs = mean_statisitcs.swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_statisitcs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(mean_statisitcs))\n",
    "for train, test in cv.split(mean_statisitcs, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(mean_statisitcs[train], labels[train])\n",
    "    preds[test] = clf.predict(mean_statisitcs[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio', 'Visual']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = epoch.get_data()\n",
    "epoch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_band(data):\n",
    "    final_variances = []\n",
    "    for d in data:\n",
    "    #     print (data.shape)\n",
    "        variances = []\n",
    "        skewnesses = []\n",
    "        kurtosises = []\n",
    "        stats = []\n",
    "        for channel in d:\n",
    "    #         print(channel.shape)\n",
    "            var = channel.var()\n",
    "            variances.append(var)\n",
    "            \n",
    "            skewness = skew(channel, axis=0)\n",
    "#             print(skewness)\n",
    "\n",
    "            skewnesses.append(skewness)\n",
    "#             print(skewness)\n",
    "            kurt = kurtosis(channel)\n",
    "            kurtosises.append(kurt)\n",
    "#         print(skewnesses)\n",
    "#         mean_skew = np.mean(skewnesses)\n",
    "#         stats.append(mean_skew)\n",
    "#         stats.append(np.mean(variances))\n",
    "        final_variances.append([variances, skewnesses, kurtosises])\n",
    "    \n",
    "    return np.array(final_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_statisitcs = get_mean_band(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kurtosis_data = mean_statisitcs.swapaxes(1,2)\n",
    "Kurtosis_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =epoch.events[:,-1]\n",
    "score2 = []\n",
    "for train,test in cv.split(Kurtosis_data,target_V_vs_A):\n",
    "    X_train = Kurtosis_data[train] \n",
    "    #print(\"shape of training features(data):\",X_train.shape)\n",
    "    y_train =labels [train] \n",
    "    #print(\"shape of training target:\",y_train.shape)\n",
    "    X_test = Kurtosis_data[test] \n",
    "    #print(\"shape of testing data:\",X_test.shape)\n",
    "    y_test = labels [test]\n",
    "    #print(\"shape of testing target:\",y_test.shape)\n",
    "    \n",
    "    #fit the model to training set\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #returns the mean accuracy on test data and labels\n",
    "    score2.append(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean classification score\", np.mean(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clf = make_pipeline(\n",
    "                    Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LinearDiscriminantAnalysis())\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(mean_statisitcs))\n",
    "for train, test in cv.split(mean_statisitcs, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(mean_statisitcs[train], labels[train])\n",
    "    preds[test] = clf.predict(mean_statisitcs[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio', 'Visual']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean classification score\", np.mean(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.events[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=epoch.drop_channels(['Lm','VEOG','Rm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.get_data=epoch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.get_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pipe = make_pipeline(Vectorizer(), \n",
    "                          StandardScaler())\n",
    "norm_pipe.fit(Kurtosis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = norm_pipe.transform(Kurtosis_data)\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
