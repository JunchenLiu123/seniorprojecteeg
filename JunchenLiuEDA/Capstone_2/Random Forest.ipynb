{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Random forest to drop the unimportant channels\n",
    "* This notebook will use random forest to classify the data and sum the features importance obtains from random forest so that we know which channels are the most important and which channels are the least important\n",
    "* The goal is to be able to using random forest as feature selection to select only the useful channels for classfication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mne.decoding import SPoC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE \n",
    "import os\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "import os.path as op\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "from scipy.stats import skew, kurtosis\n",
    "import mne \n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Batch_ArtifactFilter_Epoch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=remove_artifacts_and_create_epochs('D:\\\\USB Drive\\\\NewEEG-200s\\\\SA20140206\\\\20140206_1151.set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removebadchannel(epoch):\n",
    "    epoch.drop_channels(['Lm','Rm','VEOG'])\n",
    "    epoch.drop_channels(['STI 014'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " removebadchannel(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata=epoch.get_data()\n",
    "epoch.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Methods for convert our events into binary, 4: Language, 5:Non Language\n",
    "def filter_event_id(epoch):\n",
    "    newepoch=epoch\n",
    "    epochs=[[]]\n",
    "    j=0\n",
    "    for i in range(len(newepoch.events[:,-1])):\n",
    "        if i % 3 ==0:\n",
    "            epochs.append([])\n",
    "            j=j+1\n",
    "            epochs[j].append(epoch.events[i,-1])\n",
    "        else:\n",
    "            epochs[j].append(epoch.events[i,-1])\n",
    "    for events in epochs:\n",
    "        if  4 in events or 1 in events or 13 in events or 16 in events:\n",
    "            for i in range(len(events)):\n",
    "                    events[i]=4\n",
    "        else:\n",
    "            for i in range(len(events)):\n",
    "                    events[i]=5\n",
    "    epochs.pop(0)\n",
    "    flattened_list = [y for x in epochs for y in x]\n",
    "    for i in range(len(newepoch.events)):\n",
    "        newepoch.events[i]=flattened_list[i]\n",
    "    return newepoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=filter_event_id(epoch)\n",
    "print(epoch.events[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Classfier\n",
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the feature importances for each channels\n",
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the channels that have 0 importances\n",
    "epoch.drop_channels(['LL13','RD6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "channel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Drop channels that have 0 importances\n",
    "epoch.drop_channels(['RR13','LD6','LA5','LL2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "channel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['R13','RA5','LD3','RE1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "channel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['LB6','Z5','Z4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "channel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['Z2','Z6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "channel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['RA3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "channel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['LB5','RR10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "print(channel1.shape)\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['L11','LC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))\n",
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "print(channel1.shape)\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['RC5','R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)\n",
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))\n",
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "print(channel1.shape)\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['RB1','R4','Z14','RC2','RD7','LA4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)\n",
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))\n",
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "print(channel1.shape)\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop channels that have 0 importances\n",
    "epoch.drop_channels(['L8','LL7','L1','Z12','L12','Z7','Nasium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epoch.get_data()\n",
    "y = epoch.events[:,-1]\n",
    "vec=Vectorizer()\n",
    "X=vec.fit_transform(X)\n",
    "print(X.shape)\n",
    "from sklearn import metrics\n",
    "clf = RandomForestRegressor(n_estimators =10, random_state = 42)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred.round()))\n",
    "channel=[]\n",
    "importances = np.array(clf.feature_importances_)\n",
    "for i in range(0,len(importances),500):\n",
    "    channel.append(np.sum(importances[i:i+500]))\n",
    "    channel1=np.array(channel)\n",
    "    channel1.shape\n",
    "print(channel1.shape)\n",
    "import pandas as pd\n",
    "feature_imp = pd.Series(channel1,index=epoch.ch_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
