{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use NMF to do dimension reduction on our data\n",
    "* this notebook will make use of sklearn NMF method to do dimensional reduction on our data\n",
    "* The goal is to be able to use NMF to select only the useful features for classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mne.decoding import SPoC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator,\n",
    "                          cross_val_multiscore, LinearModel, get_coef)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE \n",
    "import os\n",
    "import os.path as op\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=mne.io.read_raw_eeglab('C:\\\\USB Drive\\\\NewEEG-200s\\\\SA20140205\\\\20140205_1230.set',preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, min_duration=1/raw.info['sfreq'], shortest_event=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_id : this dictionary is created from information from Dave's dissertation page 27\n",
    "concepts={1:'BABY',2:'BELL',3:'BIRD',4:'BURP',5:'DOG',6:'DRUM',\n",
    "              7:'KNOCK',8:'LAUGH',9:'PHONE',10:'TRAIN',11:'WATER'}\n",
    "\n",
    "event_id = {'trail_start':  31, \n",
    "            'left_button':  131, \n",
    "            'right_button': 132,\n",
    "            'congruent':    133,\n",
    "            'incongruent':  134,\n",
    "            'correct':      129,\n",
    "            'incorrect':    130,\n",
    "            # targets\n",
    "            't_baby' :        135,\n",
    "            't_bell':         136,\n",
    "            't_bird':         137,\n",
    "            't_burp':         138,\n",
    "            't_dog':          139,\n",
    "            't_drum':         140,\n",
    "            't_knock':        141,\n",
    "            't_laugh':        142,\n",
    "            't_phone':        143,\n",
    "            't_train':        144,\n",
    "            't_water':        145,\n",
    "            #flankers\n",
    "            'f_baby' :        155,\n",
    "            'f_bell':         156,\n",
    "            'f_bird':         157,\n",
    "            'f_burp':         158,\n",
    "            'f_dog':          159,\n",
    "            'f_drum':         160,\n",
    "            'f_knock':        161,\n",
    "            'f_laugh':        162,\n",
    "            'f_phone':        163,\n",
    "            'f_train':        164,\n",
    "            'f_water':        165,\n",
    "}\n",
    "# event codes 1 - 24 represent flanker and target stim codes. They are NOT explicity defined in dissertation.\n",
    "for i in range(1,13):\n",
    "    event_id[\"flanker_stim_{0}\".format(i)] = i\n",
    "    \n",
    "for j in range(13, 25):\n",
    "    event_id[\"target_stim_{0}\".format(j)] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = mne.Epochs(raw, events=events, event_id = event_id, preload = True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=epoch.get_data();\n",
    "y=epoch.events[:, 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnf= mne.decoding.UnsupervisedSpatialFilter(NMF(),average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use mnf to fit the data\n",
    "mnf_data= mnf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAC= mne.decoding.UnsupervisedSpatialFilter(PCA(25),average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Pca To fit the data\n",
    "PCA_data= PAC.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(scaler.fit(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN classcifier\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                        KNN(n_neighbors=13))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "    \n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "score = clf.score(X_test, y_test)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
