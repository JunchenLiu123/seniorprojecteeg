{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../preprocessing/Artifact_Removal/preprocecssing_helpers.ipynb\n",
    "%run ../preprocessing/StimCodes.ipynb\n",
    "%run ../Classification/ConcatEpochTrails.ipynb\n",
    "%run ../PCA/Emmanuil-PCA.ipynb\n",
    "import mne \n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC  # noqa\n",
    "from sklearn.model_selection import ShuffleSplit  # noqa\n",
    "\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\EpochedEEG'\n",
    "epoch_files = os.listdir(path)\n",
    "file = os.path.join(path, epoch_files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read epoch object \n",
    "epoch = mne.read_epochs(file, preload= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot(n_channels=3, n_epochs=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indicies of trials of epoch object\n",
    "trial_index_list = get_trial_index_list(epoch_object= epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get new events for epoch object\n",
    "new_event_list = convert_event_ids_to_stim_combinations(epoch_object=epoch,\n",
    "                                                        trial_index_list = trial_index_list,\n",
    "                                                        stim_combinations = stim_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch.events.shape)\n",
    "print(new_event_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign new events to current epoch object\n",
    "epoch.events = new_event_list\n",
    "\n",
    "# assign new event_ids to current epoch object (dictionary \n",
    "# found in ../Classification/ConcatEpochTrails.ipynb)\n",
    " \n",
    "epoch.event_id = modality_lexicality_event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification time!\n",
    "\n",
    "# Isolate audio vs visual codes\n",
    "# audio codes are < 700, # visual codes are > 700 \n",
    "# audio : 100 , visual : 101\n",
    "for event in epoch.events:\n",
    "    if event[-1] < 700:\n",
    "        event[-1] = 100\n",
    "    else:\n",
    "        event[-1] = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pipe = make_pipeline(Vectorizer(), \n",
    "                          StandardScaler())\n",
    "norm_pipe.fit(epoch.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = norm_pipe.transform(epoch.get_data())\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data[:,1].shape\n",
    "epoch.get_data()[:,:20,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(scaled_data[:,1],scaled_data[:,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do PCA to reduce dimensions and data needed for classification.\n",
    "pca = UnsupervisedSpatialFilter(PCA(28), average=False) # PCA, keep 9 components \n",
    "\n",
    "epoch_data = epoch.get_data()\n",
    "pca_data = pca.fit_transform(epoch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(pca_data))\n",
    "for train, test in cv.split(pca_data, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(pca_data[train], labels[train])\n",
    "    preds[test] = clf.predict(pca_data[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio', 'Visual']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(labels, preds)\n",
    "cm3_normalized = cm3.astype(float) / cm3.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm3_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Audio vs. Visual using Logistic Regression')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(pca_data))\n",
    "for train, test in cv.split(pca_data, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(pca_data[train], labels[train])\n",
    "    preds[test] = clf.predict(pca_data[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio', 'Visual']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce dimensions by converting the 180 ms of points in time into 3 values which are variance, skewness, and kurtosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_statisitcs = get_mean_band(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_statisitcs = mean_statisitcs.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(mean_statisitcs))\n",
    "for train, test in cv.split(mean_statisitcs, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(mean_statisitcs[train], labels[train])\n",
    "    preds[test] = clf.predict(mean_statisitcs[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio', 'Visual']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(labels, preds)\n",
    "cm3_normalized = cm3.astype(float) / cm3.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm3_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Audio vs. Visual using Logistic Regression with statistics')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this again without PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_mean_statistics = get_mean_band(epoch.get_data())\n",
    "epoch_mean_statistics = epoch_mean_statistics.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(epoch_mean_statistics))\n",
    "for train, test in cv.split(epoch_mean_statistics, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(epoch_mean_statistics[train], labels[train])\n",
    "    preds[test] = clf.predict(epoch_mean_statistics[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio', 'Visual']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(labels, preds)\n",
    "cm3_normalized = cm3.astype(float) / cm3.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm3_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Audio vs. Visual - No PCA using Logistic Regression with statistics', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_mean_statistics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = make_pipeline(Vectorizer(),\n",
    "                           StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_epoch_mean_statistics = preprocess.fit_transform(epoch_mean_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_epoch_mean_statistics,labels, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.events[:,-1][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.plot(n_channels= 20, n_epochs = 9, title = \"Preprocessed and Epoched Data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
