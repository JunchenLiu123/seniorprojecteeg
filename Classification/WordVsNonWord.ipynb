{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../preprocessing/Artifact_Removal/preprocecssing_helpers.ipynb\n",
    "%run ../preprocessing/StimCodes.ipynb\n",
    "%run ../Classification/ConcatEpochTrails.ipynb\n",
    "%run ../PCA/Emmanuil-PCA.ipynb\n",
    "%run ../preprocessing/Artifact_Removal/Extract_Describer_Events.ipynb\n",
    "# %run ../preprocessing/frequency_bands.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 15.0)\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "import numpy as np\n",
    "\n",
    "import mne \n",
    "\n",
    "from mne.decoding import Vectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mne.viz import tight_layout\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Word vs Non-word classification\n",
    "* Non word vs word classification becomes more intriicate than just classifying audio vs visual.\n",
    "    * We can say that there are word vs non-word classification tasks for both Auditory and Visual stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\stim_code_epochs'\n",
    "epoch_files = os.listdir(path)\n",
    "epoch_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Word vs Non-word EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = mne.read_epochs(os.path.join(path,epoch_files[2]), preload = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = convert_epoch_events_to_stim_combinations(epoch_object=epoch)\n",
    "epoch.events = new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#montage file\n",
    "if 'Nasium' in epoch.ch_names:\n",
    "    epoch.drop_channels(ch_names=['Nasium', 'LL4', 'L12', 'VEOG']);\n",
    "montage = mne.channels.read_montage(kind = 'ANT_DukeWaveGuard_128_electrode_montages_updated_V4')\n",
    "epoch.set_montage(montage);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_lexicality_event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.event_id = modality_lexicality_event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_band(band, epoch_object):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        returns an epoch object with a filtered frequency band\n",
    "    \n",
    "    Variables: \n",
    "        band : \n",
    "            'Theta':(4,7),\n",
    "            'Alpha':(8,12),\n",
    "            'Beta':(13,25),\n",
    "            'Gamma':(30,45)\n",
    "        epoch_object: mne.epoch\n",
    "    -----\n",
    "    returns: epoch object\n",
    "    \n",
    "    \"\"\"\n",
    "    iter_freqs = {\n",
    "        'Theta':(4,7),\n",
    "        'Alpha':(8,12),\n",
    "        'Beta':(13,25),\n",
    "        'Gamma':(30,45)\n",
    "    }\n",
    "    copy_epoch = epoch_object.copy()\n",
    "    copy_epoch.filter(l_freq= iter_freqs[band][0],\n",
    "                    h_freq = iter_freqs[band][1])\n",
    "    \n",
    "    return copy_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_epoch = get_frequency_band('Gamma', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stats = get_mean_band(gamma_epoch)\n",
    "mean_stats = mean_stats.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate word and non-word events by audio and visual.\n",
    "for event in epoch.events:\n",
    "    first_digit = int(str(event[-1])[0])\n",
    "    if first_digit%2 != 0:\n",
    "        event[-1] = 100 #lexical\n",
    "    else:\n",
    "        event[-1] = 101 # non-lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(mean_stats))\n",
    "for train, test in cv.split(mean_stats, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(mean_stats[train], labels[train])\n",
    "    preds[test] = clf.predict(mean_stats[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Lexical', 'Non-Lexical']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(labels, preds)\n",
    "cm3_normalized = cm3.astype(float) / cm3.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm3_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Lexical vs. Non-Lexical', size = 20)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45, size = 20)\n",
    "plt.yticks(tick_marks, target_names,size = 20)\n",
    "tight_layout()\n",
    "plt.ylabel('True label',size = 20)\n",
    "plt.xlabel('Predicted label',size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  X_train, X_test, y_train, y_test = train_test_split(gamma_epoch.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_channels = ['RC7','RD7','RE4','R12','R13','RR12','RR13',\n",
    "                   'LC7','LD7',';LE4','L12','L13','LL12','LL13']\n",
    "audio_channels = [x for x in epoch.ch_names if 'LD' in x or 'LC' in x or 'LA' in x\n",
    "                  or 'RD' in x or 'RC' in x or 'RA' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_channels = []\n",
    "for ch in epoch.ch_names:\n",
    "    if ch not in visual_channels and ch not in audio_channels:\n",
    "        bad_channels.append(ch)\n",
    "epoch.drop_channels(ch_names= bad_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_epoch = get_frequency_band('Gamma', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stats = get_mean_band(gamma_epoch)\n",
    "mean_stats = mean_stats.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = epoch.events[:,-1]\n",
    "preds = np.empty(len(mean_stats))\n",
    "for train, test in cv.split(mean_stats, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(mean_stats[train], labels[train])\n",
    "    preds[test] = clf.predict(mean_stats[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Lexical', 'Non-Lexical']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical vs Non-Lexical needs more though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_1 = mne.read_epochs(os.path.join(path,epoch_files[2]), preload = True)\n",
    "epoch_2 = mne.read_epochs(os.path.join(path,epoch_files[3]), preload = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = mne.concatenate_epochs([epoch_1, epoch_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#montage file\n",
    "if 'Nasium' in epoch.ch_names:\n",
    "    epoch.drop_channels(ch_names=['Nasium', 'LL4', 'L12', 'VEOG']);\n",
    "montage = mne.channels.read_montage(kind = 'ANT_DukeWaveGuard_128_electrode_montages_updated_V4')\n",
    "epoch.set_montage(montage);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split by audio and visual \n",
    "## Visual - Lexical vs Non-Lexical\n",
    "\n",
    "new_events = convert_epoch_events_to_stim_combinations(epoch)\n",
    "epoch = epoch[:-1]\n",
    "epoch.events = new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch.event_id = modality_lexicality_event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_lexicality_event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seprate labels into 4 differnt types.\n",
    "# audio - lexical \n",
    "# audio - non-lexical\n",
    "# visual- lexical\n",
    "# visual- non-lexical\n",
    "\n",
    "for event in epoch.events:\n",
    "    first_digit = int(str(event[-1])[0])\n",
    "    if event[-1] < 700  and first_digit %2 !=0:\n",
    "        #Audio - lexical\n",
    "        event[-1] = 100\n",
    "    elif event[-1] < 700 and first_digit%2 == 0:\n",
    "        #Audio - non-lexical\n",
    "        event[-1] = 101\n",
    "    elif event[-1] >700 and first_digit%2 !=0:\n",
    "        #Visual - lexical\n",
    "        event[-1] = 200\n",
    "    else:\n",
    "        # Visual non-lexical\n",
    "        event[-1] = 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gamma frequency\n",
    "gamma_epoch = get_frequency_band('Gamma', epoch[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_epoch.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stats = get_mean_band(gamma_epoch)\n",
    "mean_stats = mean_stats.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract each type of audio/visual - lexical/non-lexical event\n",
    "audio_lexical = gamma_epoch[gamma_epoch.events[:,-1] == 100]\n",
    "audio_non_lexical = gamma_epoch[gamma_epoch.events[:,-1] == 101]\n",
    "visual_lexical = gamma_epoch[gamma_epoch.events[:,-1] == 200]\n",
    "visual_non_lexical = gamma_epoch[gamma_epoch.events[:,-1] == 201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(audio_lexical.get_data().shape)\n",
    "print(audio_non_lexical.get_data().shape)\n",
    "print(visual_lexical.get_data().shape)\n",
    "print(visual_non_lexical.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine audio_lexical and audio-nonlexical\n",
    "audio_lexical_data = audio_lexical.get_data()\n",
    "audio_non_lexical_data = audio_non_lexical.get_data()[:354]\n",
    "audio_lexicality_data = np.concatenate((audio_lexical_data, audio_non_lexical_data))\n",
    "audio_lexicality_labels = np.concatenate((audio_lexical.events[:,-1], audio_non_lexical[:354].events[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stats = get_mean_band(audio_lexicality_data)\n",
    "mean_stats = mean_stats.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_lexicality_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = audio_lexicality_labels\n",
    "preds = np.empty(len(mean_stats))\n",
    "for train, test in cv.split(mean_stats, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(mean_stats[train], labels[train])\n",
    "    preds[test] = clf.predict(mean_stats[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Audio Lexical', 'Audio Non-Lexical']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(labels, preds)\n",
    "cm3_normalized = cm3.astype(float) / cm3.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm3_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Audio Lexical vs. Audio Non-Lexical', size = 30)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45, size = 30)\n",
    "plt.yticks(tick_marks, target_names,size = 30)\n",
    "tight_layout()\n",
    "plt.ylabel('True label',size = 30)\n",
    "plt.xlabel('Predicted label',size = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_epoch.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_lexical_data = visual_lexical.get_data()[:300]\n",
    "visual_non_lexical_data = visual_non_lexical.get_data()\n",
    "visual_lexicality_data = np.concatenate((visual_lexical_data, visual_non_lexical_data))\n",
    "visual_lexicality_labels = np.concatenate((visual_lexical[:300].events[:,-1], visual_non_lexical.events[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_lexicality_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_lexicality_mean_stats = (visual_lexicality_data)\n",
    "visual_lexicality_mean_stats = visual_lexicality_mean_stats.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification pipeline\n",
    "start = time.time()\n",
    "clf = make_pipeline(Vectorizer(),\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(penalty='l1'))\n",
    "end = time.time()\n",
    "print(\"clf elapsed time: {0}\".format(end - start))\n",
    "\n",
    "start_master = time.time()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "\n",
    "labels = visual_lexicality_labels\n",
    "preds = np.empty(len(visual_lexicality_mean_stats))\n",
    "for train, test in cv.split(visual_lexicality_mean_stats, labels):\n",
    "    start = time.time()\n",
    "    clf.fit(visual_lexicality_mean_stats[train], labels[train])\n",
    "    preds[test] = clf.predict(visual_lexicality_mean_stats[test])\n",
    "    end = time.time()\n",
    "    print(\"kfold elapsed time: {0}\".format(end - start))\n",
    "end = time.time()\n",
    "print(\"classification elapsed time: {0}\".format(end - start_master))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "target_names = ['Visual Lexical', 'Visual Non-Lexical']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "end = time.time()\n",
    "print(\"reporting elapsed time: {0}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3 = confusion_matrix(labels, preds)\n",
    "cm3_normalized = cm3.astype(float) / cm3.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm3_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Visual Lexical vs. Visual Non-Lexical', size = 30)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45, size = 30)\n",
    "plt.yticks(tick_marks, target_names,size = 30)\n",
    "tight_layout()\n",
    "plt.ylabel('True label',size = 30)\n",
    "plt.xlabel('Predicted label',size = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_lexality_mean_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
